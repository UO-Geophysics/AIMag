{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218cddb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 23:07:46 - mlaapde.access.MLAAPDE_Access - INFO - MLAAPDE_Access.__init__() starting\n",
      "2023-09-20 23:07:59 - mlaapde.access.MLAAPDE_Access - INFO - MLAAPDE_Access.__init__() complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/hank/mlaapde_v1b/data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ----- Imports ----- ###\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/hcole/neic-mlaapde')\n",
    "\n",
    "from mlaapde.access import MLAAPDE_Access\n",
    "from mlaapde import UTC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "\n",
    "# mlpa = MLAAPDE_Access(data_dir = '/data/hank/mlaapde_subset/data', random_seed = 616) # 3 months\n",
    "# dataset = 'subset'\n",
    "\n",
    "mlpa = MLAAPDE_Access(data_dir = '/data/hank/mlaapde_v1b/data', random_seed = 616)\n",
    "dataset = 'v1b'\n",
    "\n",
    "mlpa.data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4832e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPU, 2 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 23:07:59.371929: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-20 23:08:01.003131: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-09-20 23:08:01.003375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30466 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2023-09-20 23:08:01.004175: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 1\n",
      "2023-09-20 23:08:01.004268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30466 MB memory:  -> device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "345a365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Parameters ----- ###\n",
    "\n",
    "# Where to save the products\n",
    "# models_figs_path = '/home/sdybing/neic-mlaapde/allwaveforms/decimated/'\n",
    "models_figs_path = '/data/mlmag-weighted/'\n",
    "\n",
    "# MLAAPDE/data generation params\n",
    "#nsamp = False # Samples of waveforms to load from MLAAPDE\n",
    "#n_train_samp = 1000000\n",
    "#n_valid_samp = 200000\n",
    "#nsamp = n_train_samp + n_valid_samp\n",
    "# sr = 40 # Sampling rate\n",
    "sr = 20 # Sampling rate\n",
    "trim_sec = 60 # Trimming amount around phase pick to get from MLAAPDE\n",
    "trim_pre_sec = trim_sec\n",
    "trim_post_sec = trim_pre_sec\n",
    "window_len = trim_pre_sec + trim_post_sec\n",
    "#train_split = 0.8 # Percentage of data used in training\n",
    "#valid_split = 0.2 # Percentage of data used for validation\n",
    "n_channels = 3 # Instrument channels\n",
    "# cut_lens = [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 30, 35, 40, 50, 60, 70, 80, 90, 100, 110, 120]\n",
    "# cut_lens_finish = [80, 90, 100, 110, 120]\n",
    "cut_lens = [120]\n",
    "# test_cut_lens = [7, 8]\n",
    "\n",
    "desired_shift = 3\n",
    "max_shift = desired_shift * 2 # Since the shifting method actually makes it half what this value is set to\n",
    "min_snr_db = False\n",
    "max_snr_db = False\n",
    "log_progress_fraction = 100\n",
    "valid_phases = ['P', 'Pn', 'Pg']\n",
    "cast_dtype = np.float32\n",
    "\n",
    "# Training/model params\n",
    "epochs_number = 200\n",
    "batch_size = int(256) # Reducing to help memory\n",
    "monte_carlo_sampling = 50\n",
    "drop_rate = 0.5\n",
    "filters = [32, 64, 96, 128, 256] \n",
    "\n",
    "# Used if loading a trained model\n",
    "# training_samps = 100000 \n",
    "training_samps = False \n",
    "training_dataset = 'v1b'\n",
    "shift_status = 'shifted'\n",
    "# model_folder_path = '/home/sdybing/neic-mlaapde/allwaveforms/float32/'\n",
    "model_folder_path = '/data/mlmag-weighted/'\n",
    "\n",
    "# To make end error plots\n",
    "mean_errors = []\n",
    "std_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "321ba150",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Where are the HDF5 files getting saved? ----- ###\n",
    "\n",
    "# Location of HDF5 data files\n",
    "# hdf5_save_dir = '/data/sdybing/allwaveforms/decimated/'\n",
    "hdf5_save_dir = '/data/mlaapde/mlmag_queries/'\n",
    "# if os.path.isdir(hdf5_save_dir):\n",
    "#     pass\n",
    "# else:\n",
    "#     os.makedirs(hdf5_save_dir)\n",
    "\n",
    "# Pick extra labels and set keyword arguments for data parameters\n",
    "return_labels = ['source_magnitude', 'source_magnitude_type', 'snr_db', 'phase_id']\n",
    "kwargs = {'valid_phases':valid_phases, 'labels':return_labels, 'trim_pre_sec':trim_pre_sec, 'trim_post_sec':trim_post_sec, 'min_snr_db':min_snr_db, 'max_snr_db':max_snr_db, 'log_progress_fraction':log_progress_fraction, 'cast_dtype':cast_dtype}\n",
    "#kwargs = {'valid_phases':valid_phases, 'labels':return_labels, 'trim_pre_sec':trim_pre_sec, 'trim_post_sec':trim_post_sec, 'min_snr_db':min_snr_db, 'max_snr_db':max_snr_db, 'cast_dtype':cast_dtype}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86df4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_before = True # If this code has been run before and the HDF5 files already exist, set this to True to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "512ec5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['magnitude', 'magnitude_type', 'phase_id', 'snr_db', 'waves']\n",
      "CPU times: user 1min 28s, sys: 1min 33s, total: 3min 2s\n",
      "Wall time: 3min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### ----- Load the full dataset from HDF5 files ----- ###\n",
    "\n",
    "training_data = h5py.File(hdf5_save_dir + 'training_data_full_decimate2.hdf5', 'r')\n",
    "dataset_names = list(training_data.keys())\n",
    "print(dataset_names)\n",
    "\n",
    "train_waves = training_data['waves'][:]\n",
    "train_mags = training_data['magnitude'][:]\n",
    "train_phase_id = training_data['phase_id'][:]\n",
    "\n",
    "validation_data = h5py.File(hdf5_save_dir + 'validation_data_full_decimate2.hdf5', 'r')\n",
    "\n",
    "valid_waves = validation_data['waves'][:]\n",
    "valid_mags = validation_data['magnitude'][:]\n",
    "\n",
    "training_data.close()\n",
    "validation_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3885febc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2431341, 3, 2400)\n",
      "(2431341,)\n",
      "(489268, 3, 2400)\n",
      "(489268,)\n"
     ]
    }
   ],
   "source": [
    "print(train_waves.shape)\n",
    "print(train_mags.shape)\n",
    "print(valid_waves.shape)\n",
    "print(valid_mags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab97b66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2431341, 2400, 3)\n",
      "(2431341,)\n",
      "(489268, 2400, 3)\n",
      "(489268,)\n"
     ]
    }
   ],
   "source": [
    "train_waves_t = train_waves.transpose(0,2,1)\n",
    "valid_waves_t = valid_waves.transpose(0,2,1)\n",
    "\n",
    "print(train_waves_t.shape)\n",
    "print(train_mags.shape)\n",
    "print(valid_waves_t.shape)\n",
    "print(valid_mags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8a16d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_waves\n",
    "del valid_waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea9cd007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[741100 741100 741100 ... 741102 741102 741102]\n"
     ]
    }
   ],
   "source": [
    "isfinite = np.isfinite(train_waves_t)\n",
    "#print(isfinite)\n",
    "i = np.where(isfinite == False)[0]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46c9d85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[741100 741102]\n"
     ]
    }
   ],
   "source": [
    "k = np.unique(i)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6792405",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 741100\n",
    "idx2 = 741102\n",
    "# print(train_waves_t[idx])\n",
    "# print(train_waves_t[idx2])\n",
    "# plt.plot(train_waves_t[idx])\n",
    "# plt.show()\n",
    "# plt.plot(train_waves_t[idx2])\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7982d0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'us20002njs_CI.BAR.BH*.--_P'\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " ...\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "b'us20002njs_CI.MWC.BH*.--_P'\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " ...\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "# Fixing the weird nan wave\n",
    "\n",
    "print(train_phase_id[idx])\n",
    "print(train_waves_t[idx])\n",
    "print(train_phase_id[idx2])\n",
    "print(train_waves_t[idx2])\n",
    "\n",
    "copy_wave = train_waves_t[0]\n",
    "copy_mag = train_mags[0]\n",
    "copy_wave2 = train_waves_t[1]\n",
    "copy_mag2 = train_mags[1]\n",
    "\n",
    "train_waves_t[idx] = copy_wave\n",
    "train_mags[idx] = copy_mag\n",
    "train_waves_t[idx2] = copy_wave2\n",
    "train_mags[idx2] = copy_mag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da24aa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13537762 -0.07492092 -0.01111916]\n",
      " [ 0.14370808 -0.06007923 -0.0382474 ]\n",
      " [ 0.16341539 -0.0520903  -0.06750712]\n",
      " ...\n",
      " [ 0.07638217 -0.5865543  -0.42226908]\n",
      " [ 0.06599141 -0.54354584 -0.43552026]\n",
      " [ 0.0809005  -0.47435188 -0.44014212]]\n",
      "4.1\n",
      "4.1\n",
      "[[-0.15383083 -0.07718702  0.07553101]\n",
      " [-0.1270593   0.10472912  0.11481622]\n",
      " [-0.04937771  0.01080933 -0.01179511]\n",
      " ...\n",
      " [-0.04464537  0.09051014 -0.10665515]\n",
      " [-0.15524319  0.16512017 -0.22075841]\n",
      " [-0.13242158  0.12540203 -0.03071801]]\n",
      "4.1\n",
      "4.1\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure it's good now\n",
    "\n",
    "print(train_waves_t[idx])\n",
    "print(train_mags[idx])\n",
    "print(train_mags[0])\n",
    "\n",
    "print(train_waves_t[idx2])\n",
    "print(train_mags[idx2])\n",
    "print(train_mags[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c62dc265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2920609\n"
     ]
    }
   ],
   "source": [
    "n_train_samp = len(train_mags)\n",
    "n_valid_samp = len(valid_mags)\n",
    "nsamp = n_train_samp + n_valid_samp\n",
    "print(nsamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ffaffa",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# mag-weight prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e7a01d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_mags = len(train_mags)\n",
    "\n",
    "# w_bins = {}\n",
    "\n",
    "# for i in np.arange(0,10.5,0.5):\n",
    "#     if i==0:\n",
    "#         bin_mag_min=i\n",
    "#         continue\n",
    "#     bin_mag_max=i\n",
    "    \n",
    "#     #do bin work\n",
    "#     bin_count = train_mags[train_mags>=bin_mag_min]\n",
    "#     bin_count = len(bin_count[bin_count<bin_mag_max])\n",
    "    \n",
    "#     w_bins[bin_mag_min] = {}\n",
    "#     bin_range = [bin_mag_min, bin_mag_max]\n",
    "#     w_bins[bin_mag_min]['range'] = bin_range\n",
    "#     w_bins[bin_mag_min]['count'] = bin_count\n",
    "    \n",
    "#     weight = 1-bin_count/n_mags\n",
    "#     if bin_count==0:\n",
    "#         w_bins[bin_mag_min]['weight'] = 1\n",
    "#     else:\n",
    "#         w_bins[bin_mag_min]['weight'] = weight\n",
    "    \n",
    "#     bin_mag_min=i\n",
    "        \n",
    "#     print(f'bin: {bin_range}  n={bin_count}  w={weight:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11f6ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _weight_for_mag(mag_value):\n",
    "#     mag_idx = round(int(2*mag_value))/2\n",
    "#     wbin = w_bins[mag_idx]\n",
    "#     print(f'mag={mag_value}  bin_range={wbin[\"range\"]}  weight={wbin[\"weight\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "797ab8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_weight_bins(train_mags):\n",
    "\n",
    "    n_mags = len(train_mags)\n",
    "    w_bins = {}\n",
    "\n",
    "    for i in np.arange(0,10.5,0.5):\n",
    "        if i==0:\n",
    "            bin_mag_min=i\n",
    "            continue\n",
    "        bin_mag_max=i\n",
    "\n",
    "        bin_count = train_mags[train_mags>=bin_mag_min]\n",
    "        bin_count = len(bin_count[bin_count<bin_mag_max])\n",
    "        w_bins[bin_mag_min] = {}\n",
    "        bin_range = [bin_mag_min, bin_mag_max]\n",
    "        w_bins[bin_mag_min]['range'] = bin_range\n",
    "\n",
    "        weight = 1-bin_count/n_mags\n",
    "        if bin_count==0:\n",
    "            w_bins[bin_mag_min]['weight'] = 1\n",
    "        else:\n",
    "            w_bins[bin_mag_min]['weight'] = weight\n",
    "\n",
    "        bin_mag_min=i\n",
    "\n",
    "    return w_bins\n",
    "\n",
    "def _weight_from_mag(wbins, mag_value):\n",
    "    mag_idx = round(int(2*mag_value))/2\n",
    "    wbin = wbins[mag_idx]\n",
    "    return wbin['range'], wbin['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7506506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbins = _build_weight_bins(train_mags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1adb4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6.0, 6.5], 0.9790950755159396)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_weight_from_mag(wbins, 6.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ce86b6",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf326853",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### -------- Functions -------- #####\n",
    "\n",
    "### ----- Predictions ----- ###\n",
    "\n",
    "class KerasDropoutPrediction(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, x, n_iter = 10):\n",
    "        predM = []\n",
    "        auM = []\n",
    "\n",
    "        for itr in range(n_iter):\n",
    "\n",
    "            if itr == 0:\n",
    "                print('Making predictions...')\n",
    "            r = model.predict(x, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "            pred = r[:, 0] \n",
    "            au = r[:, 1] \n",
    "            predM.append(pred.T)\n",
    "            auM.append(au.T)\n",
    "\n",
    "        predM = np.array(predM).reshape(n_iter, len(predM[0]))\n",
    "        auM = np.array(auM).reshape(n_iter, len(auM[0])) \n",
    "\n",
    "        yhat_mean = predM.mean(axis = 0)\n",
    "        yhat_squared_mean = np.square(predM).mean(axis = 0)\n",
    "\n",
    "        sigma_squared = 10**(auM)  # should be e, not 10?\n",
    "        sigma_squared_mean = sigma_squared.mean(axis = 0)\n",
    "\n",
    "        ep_unc = predM.std(axis = 0)  \n",
    "\n",
    "        combined = yhat_squared_mean - np.square(yhat_mean) + sigma_squared_mean\n",
    "\n",
    "        return yhat_mean, sigma_squared_mean, ep_unc, combined\n",
    "\n",
    "### ----- Training setup ----- ###\n",
    "\n",
    "def customLoss(yTrue, yPred):\n",
    "    y_hat = K.reshape(yPred[:, 0], [-1, 1]) \n",
    "    s = K.reshape(yPred[:, 1], [-1, 1])\n",
    "    return tf.reduce_sum(0.5 * K.exp(-1 * s) * K.square(K.abs(yTrue - y_hat)) + 0.5 * s, axis=1)\n",
    "\n",
    "### ----- Training callbacks ----- ###\n",
    "\n",
    "class PrintSomeValues(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs = {}):\n",
    "        print()\n",
    "        print(f'y_test[0:1] = {valid_mags[0:1]}.')\n",
    "        print(f'pred = {self.model.predict(shift_valid_waves_t[0:1])}.')\n",
    "\n",
    "### ----- Data generator ----- ###\n",
    "\n",
    "debug_generator = False\n",
    "debug_plot = False\n",
    "\n",
    "class dataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, train_waves_t, train_mags, n_train_samp, window_len, cut_len, max_shift, sr, batch_size, n_channels, shuff = True, noise_rate = 0.5, flip_rate = 0.5, dropchan_rate = 0.05):\n",
    "    #def __init__(self, train_waves_t, train_mags, nsamp, window_len, cut_len, max_shift, sr, train_split, batch_size, n_channels, shuff = True, noise_rate = 0, flip_rate = 0, dropchan_rate = 0):\n",
    "        self.train_waves_t = train_waves_t\n",
    "        self.train_mags = train_mags\n",
    "        self.n_train_samp = n_train_samp\n",
    "        self.window_len = window_len\n",
    "        self.cut_len = cut_len\n",
    "        self.max_shift = max_shift\n",
    "        self.shift_len = self.cut_len - self.max_shift\n",
    "        self.sr = sr\n",
    "        self.shuff = shuff\n",
    "        self.batch_size = batch_size\n",
    "        self.full_lengthpts = int(self.window_len * self.sr)\n",
    "        self.cut_lengthpts = int(self.cut_len * self.sr)\n",
    "        self.shift_lengthpts = int(self.shift_len * self.sr)\n",
    "        self.lentraindata = int(self.n_train_samp)\n",
    "        self.middle = int(self.full_lengthpts / 2)\n",
    "        self.n_channels = n_channels\n",
    "        self.on_epoch_end()\n",
    "        self.noise_rate = noise_rate\n",
    "        self.flip_rate = flip_rate\n",
    "        self.dropchan_rate = dropchan_rate\n",
    "        \n",
    "        self.weight_bins = None\n",
    "        self.weight_bins = self._build_weight_bins(train_mags)\n",
    "        \n",
    "    def _build_weight_bins(self, train_mags):\n",
    "        \n",
    "        n_mags = len(train_mags)\n",
    "        w_bins = {}\n",
    "\n",
    "        for i in np.arange(0,10.5,0.5):\n",
    "            if i==0:\n",
    "                bin_mag_min=i\n",
    "                continue\n",
    "            bin_mag_max=i\n",
    "\n",
    "            bin_count = train_mags[train_mags>=bin_mag_min]\n",
    "            bin_count = len(bin_count[bin_count<bin_mag_max])\n",
    "            w_bins[bin_mag_min] = {}\n",
    "            bin_range = [bin_mag_min, bin_mag_max]\n",
    "            w_bins[bin_mag_min]['range'] = bin_range\n",
    "\n",
    "            weight = 1-bin_count/n_mags\n",
    "            if bin_count==0:\n",
    "                w_bins[bin_mag_min]['weight'] = 1\n",
    "            else:\n",
    "                w_bins[bin_mag_min]['weight'] = weight\n",
    "\n",
    "            bin_mag_min=i\n",
    "          \n",
    "        return w_bins\n",
    "    \n",
    "    def _weight_from_mag(self, mag_value):\n",
    "        mag_idx = round(int(2*mag_value))/2\n",
    "        wbin = self.weight_bins[mag_idx]\n",
    "        return wbin['weight']\n",
    "\n",
    "    def on_epoch_end(self): # Modify dataset between epochs\n",
    "        self.indexes = np.arange(self.lentraindata, dtype = int) # Array of integers for the training data length\n",
    "        if self.shuff == True:\n",
    "            np.random.shuffle(self.indexes) # Shuffle those indices if indicated\n",
    "\n",
    "    def __len__(self) : # Number of batches in the sequences\n",
    "        return int(self.lentraindata / self.batch_size) # Length of training data divided by the chosen batch size\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        \n",
    "        # Initialization\n",
    "        if debug_generator: print('Initial empty shapes!')\n",
    "        y = np.ones((self.batch_size,))\n",
    "        \n",
    "        w = np.ones((self.batch_size,)) #weight init\n",
    "        \n",
    "        full_x = np.zeros((self.batch_size, self.full_lengthpts, self.n_channels)) # Shape is batch size by number of samples (window * sps) by number of channels\n",
    "        if debug_generator: print('Full X shape:' + str(full_x.shape))\n",
    "        \n",
    "        cut_x = np.zeros((self.batch_size, self.cut_lengthpts, self.n_channels)) # Shape is batch size by number of samples (window * sps) by number of channels\n",
    "        if debug_generator: print('Cut X shape:' + str(cut_x.shape))\n",
    "        \n",
    "        shift_x = np.zeros((self.batch_size, self.shift_lengthpts, self.n_channels)) # Shape is batch size by number of samples (window * sps) by number of channels\n",
    "        if debug_generator: print('Shift X shape:' + str(shift_x.shape))\n",
    "            \n",
    "        x = shift_x.copy()\n",
    "    \n",
    "        # Make the augmentations\n",
    "        for i, ix in enumerate(indexes):\n",
    "            n = 0 # Counter to prevent dropping 3 channels\n",
    "            \n",
    "            if debug_generator: print('Augmenting!')\n",
    "            if debug_plot:\n",
    "                wvf_idx = np.random.choice(np.arange(0,len(self.train_mags),1))\n",
    "                #wvf_idx = 507\n",
    "                if i == wvf_idx:\n",
    "                    print('Waveform index: ' + str(wvf_idx))\n",
    "                    def plot_features(axis):\n",
    "                        axis.legend(loc = 'upper left', fontsize = 14)\n",
    "                        axis.set_xlim(0,self.shift_len)\n",
    "                        axis.set_ylim(-1.2,1.2)\n",
    "                        axis.axvline(self.shift_len/2, color = 'black', linestyle = '--', alpha = 0.7)\n",
    "                        axis.tick_params(axis = 'x', bottom = False, labelbottom = False)\n",
    "                    f, ((a0, a1, a2), (a3, a4, a5), (a6, a7, a8), (a9, a10, a11), (a12, a13, a14), (a15, a16, a17), (a18, a19, a20)) = plt.subplots(nrows = 7, ncols = 3, gridspec_kw={'height_ratios': [1, 1, 1, 0.75, 1, 1, 1]}, figsize = (22,10), dpi=300, facecolor = 'white')\n",
    "\n",
    "            # Original waveforms\n",
    "            if debug_generator: print(ix)\n",
    "            full_x[i,] = self.train_waves_t[ix,:,0:3]\n",
    "            y[i,] = self.train_mags[ix,]\n",
    "            w[i,] = self._weight_from_mag(self.train_mags[ix,])\n",
    "            if debug_generator: print('Original full lengthpts: ' + str(self.full_lengthpts))\n",
    "            if debug_generator: print('Original full x shape: ' + str(full_x.shape))\n",
    "            if debug_plot:\n",
    "                if i == wvf_idx:\n",
    "                    times = np.arange(0, self.window_len, 1/self.sr)\n",
    "                    \n",
    "                    a0.set_title('Original waveforms', fontsize = 16)\n",
    "                    a0.plot(times, full_x[i,:,0], color = 'C0', label = 'E') \n",
    "                    a0.legend(loc = 'upper left', fontsize = 14)\n",
    "                    a0.set_xlim(0,self.window_len)\n",
    "                    a0.set_ylim(-1.2,1.2)\n",
    "                    a0.axvline(self.window_len/2, color = 'black', linestyle = '--', alpha = 0.7)\n",
    "                    a0.tick_params(axis = 'x', bottom = False, labelbottom = False)\n",
    "\n",
    "                    a3.plot(times, full_x[i,:,1], color = 'C1', label = 'N')\n",
    "                    a3.set_ylabel('Stream-normalized amplitude', fontsize = 14)\n",
    "                    a3.legend(loc = 'upper left', fontsize = 14)\n",
    "                    a3.set_xlim(0,self.window_len)\n",
    "                    a3.set_ylim(-1.2,1.2)\n",
    "                    a3.axvline(self.window_len/2, color = 'black', linestyle = '--', alpha = 0.7)\n",
    "                    a3.tick_params(axis = 'x', bottom = False, labelbottom = False)\n",
    "\n",
    "                    a6.plot(times, full_x[i,:,2], color = 'C2', label = 'Z')\n",
    "                    a6.set_xlabel('Time (s)', fontsize = 14)\n",
    "                    a6.legend(loc = 'upper left', fontsize = 14)\n",
    "                    a6.set_xlim(0,self.window_len)\n",
    "                    a6.set_ylim(-1.2,1.2)\n",
    "                    a6.axvline(self.window_len/2, color = 'black', linestyle = '--', alpha = 0.7)\n",
    "                    a6.tick_params(axis = 'x', bottom = True, labelbottom = True)\n",
    "\n",
    "            # Cut to the window length \n",
    "            cut_x[i,] = full_x[i, int(self.middle - (self.cut_len/2)*self.sr) : int(self.middle + (self.cut_len/2)*self.sr), 0:3]\n",
    "            if debug_generator: print('Cut lengthpts: ' + str(self.cut_lengthpts))\n",
    "            if debug_generator: print('Cut x shape: ' + str(cut_x.shape))\n",
    "            if debug_plot:\n",
    "                if i == wvf_idx:\n",
    "                    cut_times = np.arange(0, self.cut_len, 1/self.sr)\n",
    "\n",
    "                    a1.set_title('Trimming to desired window length', fontsize = 16)\n",
    "                    a1.plot(cut_times, cut_x[i,:,0], color = 'C0', label = 'E')\n",
    "                    a1.legend(loc = 'upper left', fontsize = 14)\n",
    "                    a1.set_xlim(0,self.cut_len)\n",
    "                    a1.set_ylim(-1.2,1.2)\n",
    "                    a1.axvline(self.cut_len/2, color = 'black', linestyle = '--', alpha = 0.7)\n",
    "                    a1.tick_params(axis = 'x', bottom = False, labelbottom = False)\n",
    "\n",
    "                    a4.plot(cut_times, cut_x[i,:,1], color = 'C1', label = 'N')\n",
    "                    a4.set_ylabel('Stream-normalized amplitude', fontsize = 14)\n",
    "                    a4.legend(loc = 'upper left', fontsize = 14)\n",
    "                    a4.set_xlim(0,self.cut_len)\n",
    "                    a4.set_ylim(-1.2,1.2)\n",
    "                    a4.axvline(self.cut_len/2, color = 'black', linestyle = '--', alpha = 0.7)\n",
    "                    a4.tick_params(axis = 'x', bottom = False, labelbottom = False)\n",
    "\n",
    "                    a7.plot(cut_times, cut_x[i,:,2], color = 'C2', label = 'Z')\n",
    "                    a7.set_xlabel('Time (s)', fontsize = 14)\n",
    "                    a7.legend(loc = 'upper left', fontsize = 14)\n",
    "                    a7.set_xlim(0,self.cut_len)\n",
    "                    a7.set_ylim(-1.2,1.2)\n",
    "                    a7.axvline(self.cut_len/2, color = 'black', linestyle = '--', alpha = 0.7)\n",
    "                    a7.tick_params(axis = 'x', bottom = True, labelbottom = True)\n",
    "            \n",
    "            # Shifting up to 3 seconds\n",
    "            self.time_offset = np.random.uniform(low = 0, high = self.max_shift) # seconds\n",
    "            self.samps_offset = int(self.time_offset * self.sr)\n",
    "            self.start = self.samps_offset\n",
    "            self.end = int(self.start + self.shift_len * self.sr)\n",
    "            shift_x[i,] = cut_x[i, self.start : self.end, 0:3]\n",
    "            if debug_generator: print('Shift lengthpts: ' + str(self.shift_lengthpts))\n",
    "            if debug_generator: print('Shift x shape: '  + str(shift_x.shape))\n",
    "            if debug_plot:\n",
    "                if i == wvf_idx:\n",
    "                    print(self.time_offset)\n",
    "                    print(self.shift_len)\n",
    "                    shift_times = np.arange(0, self.shift_len, 1/self.sr)\n",
    "\n",
    "                    a2.set_title('Shifted ' + str(round(self.time_offset,1)) + ' seconds', fontsize = 16)\n",
    "                    a2.plot(shift_times, shift_x[i,:,0], color = 'C0', label = 'E')\n",
    "                    plot_features(a2)\n",
    "\n",
    "                    a5.plot(shift_times, shift_x[i,:,1], color = 'C1', label = 'N')\n",
    "                    a5.set_ylabel('Stream-normalized amplitude', fontsize = 14)\n",
    "                    plot_features(a5)\n",
    "\n",
    "                    a8.plot(shift_times, shift_x[i,:,2], color = 'C2', label = 'Z')\n",
    "                    a8.set_xlabel('Time (s)', fontsize = 14)\n",
    "                    plot_features(a8)\n",
    "                    a8.tick_params(axis = 'x', bottom = True, labelbottom = True)\n",
    "            \n",
    "            x[i,] = shift_x[i,]\n",
    "            if debug_generator: print('Renamed to x shape: ' + str(x.shape))\n",
    "            \n",
    "            # Add extra noise\n",
    "            if(np.random.random() < self.noise_rate):\n",
    "                x[i,:,0] = x[i,:,0] + np.random.normal(0, np.random.uniform(0.01, 0.15), self.shift_lengthpts)\n",
    "                x[i,:,1] = x[i,:,1] + np.random.normal(0, np.random.uniform(0.01, 0.15), self.shift_lengthpts)\n",
    "                x[i,:,2] = x[i,:,2] + np.random.normal(0, np.random.uniform(0.01, 0.15), self.shift_lengthpts)\n",
    "            if debug_plot:\n",
    "                if i == wvf_idx:\n",
    "                    a12.set_title('Extra noise', fontsize = 16)\n",
    "                    a12.plot(shift_times, x[i,:,0], color = 'C0', label = 'E') \n",
    "                    plot_features(a12)\n",
    "\n",
    "                    a15.plot(shift_times, x[i,:,1], color = 'C1', label = 'N')\n",
    "                    a15.set_ylabel('Stream-normalized amplitude', fontsize = 14)\n",
    "                    plot_features(a15)\n",
    "\n",
    "                    a18.plot(shift_times, x[i,:,2], color = 'C2', label = 'Z')\n",
    "                    a18.set_xlabel('Time (s)', fontsize = 14)\n",
    "                    plot_features(a18)\n",
    "                    a18.tick_params(axis = 'x', bottom = True, labelbottom = True)\n",
    "            x[i,] = x[i,] / np.max(np.abs(x[i,])) # normalizing again now that it's cut\n",
    "\n",
    "            # Flip horizontal channels\n",
    "            if(np.random.random() < self.flip_rate):\n",
    "                flip =  x[i,:,0].copy()\n",
    "                x[i,:,0] =  x[i,:,1]\n",
    "                x[i,:,1] =  flip\n",
    "            if debug_plot:\n",
    "                if i == wvf_idx:\n",
    "                    a13.set_title('Flip horizontal components', fontsize = 16)\n",
    "                    a13.plot(shift_times, x[i,:,0], color = 'C0', label = 'E') \n",
    "                    plot_features(a13)\n",
    "\n",
    "                    a16.plot(shift_times, x[i,:,1], color = 'C1', label = 'N')\n",
    "                    a16.set_ylabel('Stream-normalized amplitude', fontsize = 14)\n",
    "                    plot_features(a16)\n",
    "\n",
    "                    a19.plot(shift_times, x[i,:,2], color = 'C2', label = 'Z')\n",
    "                    a19.set_xlabel('Time (s)', fontsize = 14)\n",
    "                    plot_features(a19)\n",
    "                    a19.tick_params(axis = 'x', bottom = True, labelbottom = True)\n",
    "            \n",
    "            # Drop channels\n",
    "            if(np.random.random() < self.dropchan_rate):\n",
    "                x[i,:,0] = 0\n",
    "                n += 1\n",
    "            if(np.random.random() < self.dropchan_rate):\n",
    "                x[i,:,1] = 0\n",
    "                n += 1\n",
    "            if(np.random.random() < self.dropchan_rate):\n",
    "                if n == 2:\n",
    "                    pass\n",
    "                else:\n",
    "                    x[i,:,2] = 0\n",
    "            if debug_plot:\n",
    "                if i == wvf_idx:\n",
    "                    a14.set_title('Drop channel', fontsize = 16)\n",
    "                    a14.plot(shift_times, x[i,:,0], color = 'C0', label = 'E') \n",
    "                    plot_features(a14)\n",
    "\n",
    "                    a17.plot(shift_times, x[i,:,1], color = 'C1', label = 'N')\n",
    "                    a17.set_ylabel('Stream-normalized amplitude', fontsize = 14)\n",
    "                    plot_features(a17)\n",
    "\n",
    "                    a20.plot(shift_times, x[i,:,2], color = 'C2', label = 'Z')\n",
    "                    a20.set_xlabel('Time (s)', fontsize = 14)\n",
    "                    plot_features(a20)\n",
    "                    a20.tick_params(axis = 'x', bottom = True, labelbottom = True)\n",
    "            \n",
    "            if debug_plot:\n",
    "                if i == wvf_idx:\n",
    "                    a9.set_visible(False)\n",
    "                    a10.set_visible(False)\n",
    "                    a11.set_visible(False)\n",
    "\n",
    "                    plt.subplots_adjust(hspace = 0)\n",
    "                    plt.show()\n",
    "                    plt.close();\n",
    "            \n",
    "            if debug_generator: print('Final x shape: ' + str(x.shape))\n",
    "\n",
    "        return x, y, w\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        iii = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        x, y, w = self.__data_generation(iii)\n",
    "\n",
    "        return x, y, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bef10917",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_figs_path = '/data/mlmag-weighted/'\n",
    "model_folder_path = '/data/mlmag-weighted/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09879e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut len: 120\n",
      "\n",
      "y_test[0:1] = [2.2].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 15:04:55.775180: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8401\n",
      "2023-09-21 15:04:58.111893: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: Cannot allocate memory\n",
      "2023-09-21 15:04:58.235172: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: Cannot allocate memory\n",
      "2023-09-21 15:04:58.354745: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: Cannot allocate memory\n",
      "2023-09-21 15:04:58.354827: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-09-21 15:04:58.480924: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: Cannot allocate memory\n",
      "2023-09-21 15:04:58.481145: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred = [[-0.02190194]].\n",
      "Epoch 1/200\n",
      "9497/9497 [==============================] - ETA: 0s - loss: 0.4427"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 15:29:06.754275: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 13386372480 exceeds 10% of free system memory.\n",
      "2023-09-21 15:29:23.686668: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 13386372480 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49254, saving model to /data/mlmag-weighted/v1b_2920609samps_114s_window/v1b_2920609samps_114s_001.h5\n",
      "9497/9497 [==============================] - 1598s 168ms/step - loss: 0.4427 - val_loss: 0.4925 - lr: 0.0010\n",
      "\n",
      "y_test[0:1] = [2.2].\n",
      "pred = [[3.7426298]].\n",
      "Epoch 2/200\n",
      "4815/9497 [==============>...............] - ETA: 11:39 - loss: 0.3386"
     ]
    }
   ],
   "source": [
    "########## STUFF THAT NEEDS LOOPING ##########\n",
    "\n",
    "debug = False\n",
    "\n",
    "# for cut_len in cut_lens_finish:\n",
    "for cut_len in cut_lens:\n",
    "    print('Cut len: ' + str(cut_len))\n",
    "    \n",
    "    ### ----- Where are the trained models/figures getting saved? ----- ###\n",
    "\n",
    "    save_dir = models_figs_path + str(dataset) + '_' + str(nsamp) + 'samps_' + str(cut_len-6) + 's_window'\n",
    "#     if os.path.isdir(save_dir):\n",
    "#         pass\n",
    "#     else: # deletes directory to start over: shutil.rmtree(save_dir)  \n",
    "#         os.makedirs(save_dir)\n",
    "\n",
    "    ### ----- Cut and shift validation data to match the training data ----- ###\n",
    "\n",
    "    ## Cut ##\n",
    "    if debug:\n",
    "        rand = np.random.choice(np.arange(0,len(valid_mags),1))\n",
    "        print('Rand: ' + str(rand))\n",
    "        valid_times = np.arange(0, window_len, 1/sr)\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Original validation data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(valid_times, valid_waves_t[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(valid_times, valid_waves_t[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(valid_times, valid_waves_t[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "    \n",
    "    middle = int(valid_waves_t.shape[1] / 2)\n",
    "    if debug: print('Middle: ' + str(middle))\n",
    "    valid_size = int(n_valid_samp)\n",
    "    if debug: print('Valid size: ' + str(valid_size))\n",
    "    cut_valid_waves_t = np.zeros((valid_size, int(cut_len*sr), 3)) \n",
    "    if debug: print('Cut waves t shape: ' + str(cut_valid_waves_t.shape))\n",
    "\n",
    "    for i in range(len(valid_waves_t)):\n",
    "        cut_valid_waves_t[i,] = valid_waves_t[i, int(middle - (cut_len/2)*sr) : int(middle + (cut_len/2)*sr), 0:3]\n",
    "    if debug: print('Cut waves t shape: ' + str(cut_valid_waves_t.shape))\n",
    "    if debug:\n",
    "        valid_cut_times = np.arange(0, cut_len, 1/sr)\n",
    "        print('Rand: ' + str(rand))\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Cut validation data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(valid_cut_times, cut_valid_waves_t[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(valid_cut_times, cut_valid_waves_t[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(valid_cut_times, cut_valid_waves_t[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "\n",
    "    ## Shift ##\n",
    "    shift_len = cut_len - max_shift\n",
    "    if debug: print('Shift len: ' + str(shift_len))\n",
    "    time_offset = np.random.uniform(low = 0, high = max_shift, size = valid_size)\n",
    "    shift_valid_waves_t = np.zeros((valid_size, int(shift_len * sr), 3)) \n",
    "\n",
    "    for ii, offset in enumerate(time_offset):\n",
    "        bin_offset = int(offset * sr)\n",
    "        start_bin = bin_offset \n",
    "        end_bin = int(start_bin + shift_len * sr)\n",
    "        shift_valid_waves_t[ii, :, 0] = cut_valid_waves_t[ii, start_bin:end_bin, 0] \n",
    "        shift_valid_waves_t[ii, :, 1] = cut_valid_waves_t[ii, start_bin:end_bin, 1]\n",
    "        shift_valid_waves_t[ii, :, 2] = cut_valid_waves_t[ii, start_bin:end_bin, 2]\n",
    "\n",
    "    if debug: print('Shift waves t shape: ' + str(shift_valid_waves_t.shape))\n",
    "    if debug:\n",
    "        valid_shift_times = np.arange(0, shift_len, 1/sr)\n",
    "        print('Rand: ' + str(rand))\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Shifted validation data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(valid_shift_times, shift_valid_waves_t[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(valid_shift_times, shift_valid_waves_t[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(valid_shift_times, shift_valid_waves_t[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "\n",
    "    ### ----- Initialize the model and training setup ----- ###\n",
    "    \n",
    "    inp1 = tf.keras.layers.Input(shape = ((cut_len - max_shift)*sr, n_channels), name = 'input_layer') \n",
    "    e = tf.keras.layers.Conv1D(filters[1], 3, padding = 'same')(inp1) \n",
    "    e = tf.keras.layers.Dropout(drop_rate)(e, training = True)\n",
    "    e = tf.keras.layers.MaxPooling1D(4, padding = 'same')(e)\n",
    "    e = tf.keras.layers.Conv1D(filters[0], 3, padding = 'same')(e) \n",
    "    e = tf.keras.layers.Dropout(drop_rate)(e, training = True)\n",
    "    e = tf.keras.layers.MaxPooling1D(4, padding = 'same')(e)\n",
    "    e = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences = False, dropout = 0.0, recurrent_dropout = 0.0))(e)\n",
    "    #e = tf.keras.layers.Dense(2)(e)\n",
    "    e = tf.keras.layers.Dense(1)(e)\n",
    "    o = tf.keras.layers.Activation('linear', name = 'output_layer')(e)\n",
    "    model = tf.keras.models.Model(inputs = [inp1], outputs = o)\n",
    "    #model.summary()\n",
    "\n",
    "    #model.compile(optimizer = 'Adam', loss = customLoss)\n",
    "    model.compile(optimizer = 'Adam', loss = tf.keras.losses.MeanSquaredError())\n",
    "    \n",
    "    model_name = str(dataset) + '_' + str(nsamp) + 'samps_' + str(shift_len) + 's'\n",
    "    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor = np.sqrt(0.1), cooldown = 0, patience = 4, min_lr = 0.5e-6)\n",
    "    m_name = str(model_name) + '_{epoch:03d}.h5' \n",
    "    filepath = os.path.join(save_dir, m_name)\n",
    "    early_stopping_monitor = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = filepath, monitor = 'val_loss', mode = 'auto', verbose = 1, save_best_only = True)\n",
    "    psv = PrintSomeValues()\n",
    "    callbacks = [lr_reducer, early_stopping_monitor, checkpoint, psv]\n",
    "    training_generator = dataGenerator(train_waves_t, train_mags, n_train_samp, window_len, cut_len, max_shift, sr, batch_size, n_channels)\n",
    "\n",
    "    ### ----- Train ----- ###\n",
    "\n",
    "    history = model.fit(training_generator, epochs = epochs_number, validation_data = (shift_valid_waves_t, valid_mags), callbacks = callbacks);\n",
    "\n",
    "    ### ----- Plot training curves ----- ###\n",
    "\n",
    "    plt.figure(facecolor = 'white')\n",
    "    plt.plot(history.history['loss'],label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    #plt.show()\n",
    "    plt.savefig(save_dir + '/loss_curves_' + m_name + '.png')\n",
    "    plt.close();\n",
    "\n",
    "    ### ----- Make the predictions ----- ###\n",
    "\n",
    "    #kdp = KerasDropoutPrediction(model)\n",
    "    #predict, al_unc, ep_unc, comb = kdp.predict(shift_valid_waves_t, monte_carlo_sampling)\n",
    "    predict = model.predict(shift_valid_waves_t)\n",
    "\n",
    "    ### ----- Quick plot of the predictions vs. true magnitudes ----- ###\n",
    "\n",
    "    fig4, ax = plt.subplots(facecolor = 'white')\n",
    "    ax.scatter(valid_mags, predict, alpha = 0.4, facecolors = 'r', edgecolors = 'r')\n",
    "    ax.plot([valid_mags.min(), valid_mags.max()], [valid_mags.min(), valid_mags.max()], 'k--', alpha=1, lw=2)\n",
    "    ax.set_xlabel('Measured magnitude')\n",
    "    ax.set_ylabel('Predicted magnitude')\n",
    "    #plt.show()\n",
    "    fig4.savefig(save_dir + '/scatter_' + m_name + '.png')\n",
    "    plt.close();\n",
    "\n",
    "    ### ----- Rename things ----- ###\n",
    "\n",
    "    measured_mags = valid_mags\n",
    "    predicted_mags = predict.flatten()\n",
    "\n",
    "    ### ----- Calculate the error and standard deviation ----- ###\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    for idx in range(len(predicted_mags)):\n",
    "        predicted = predicted_mags[idx]\n",
    "        measured = measured_mags[idx]\n",
    "        error = predicted - measured\n",
    "        errors.append(error)\n",
    "\n",
    "    mean_error = np.mean(np.array(errors))\n",
    "    std_error = np.std(np.array(errors))\n",
    "\n",
    "    print('Mean error: ' + str(round(mean_error,3)))\n",
    "    print('Error standard deviation: ' + str(round(std_error,2)))\n",
    "\n",
    "    mean_errors.append(mean_error)\n",
    "    std_errors.append(std_error)\n",
    "\n",
    "    ### ----- Make the box and whisker plots with STF magnitude line ----- ###\n",
    "\n",
    "    Tt = shift_len / 2\n",
    "    M0_dyncm = Tt**3 * (0.625 * 10**23)\n",
    "    Mw = ((2/3) * np.log10(M0_dyncm)) - 10.73 # M0 in dyne-cm\n",
    "\n",
    "    print('Rupture duration: ' + str(Tt) + ' seconds')\n",
    "    print('M0: ' + str(M0_dyncm) + ' dyne-cm')\n",
    "    print('Mw: ' + str(round(Mw,2)))\n",
    "\n",
    "    bins = np.arange(11,85,1)/10\n",
    "    data_bins = []\n",
    "\n",
    "    for abin in bins:\n",
    "        i = np.where(valid_mags == abin)[0]\n",
    "        predict_bin = np.array(predicted_mags[i])\n",
    "        data_bins.append(predict_bin)\n",
    "\n",
    "    fig = plt.figure(figsize =(14, 9), dpi = 300, facecolor = 'white')\n",
    "\n",
    "    fig.suptitle('MLAAPDE ' + str(dataset) + ' agumented dataset, tested with ' + str(int(n_valid_samp)) + ' ' + str(shift_len) + 's window samples shifted up to 3s', fontsize = 18, y = 0.96, color = 'black')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.text(x = 30, y = 8.8, s = 'Model: ' + m_name, fontsize = 13, color = 'black')\n",
    "    ax.grid(which = 'major', axis = 'y')\n",
    "    ax.grid(which = 'major', axis = 'x', markevery = [10,20,30,40,50])\n",
    "    ax.set_ylim(1,8.6)\n",
    "\n",
    "    bp = ax.boxplot(data_bins, notch = False, patch_artist = True)\n",
    "    ax.axvline((Mw-1)*10, color = 'green', linestyle = '--', linewidth = 2) # Position = (magnitude - 1)*10\n",
    "\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor('lightblue')\n",
    "        patch.set_edgecolor('blue')\n",
    "    for median in bp['medians']:\n",
    "        median.set(color ='blue', linewidth = 3)\n",
    "    for whisker in bp['whiskers']:\n",
    "        whisker.set(color ='blue', linewidth = 1)\n",
    "    for cap in bp['caps']:\n",
    "        cap.set(color ='blue', linewidth = 1)\n",
    "    for flier in bp['fliers']:\n",
    "        flier.set(marker ='+', color ='blue', alpha = 0.5)\n",
    "\n",
    "    bins_list = bins.tolist()\n",
    "    ax.set_xticklabels(bins_list, fontsize = 14, color = 'black')\n",
    "    ax.set_yticklabels([1, 2, 3, 4, 5, 6, 7, 8], fontsize = 14, color = 'black')\n",
    "    ax.set_ylabel('Predicted magnitude', fontsize = 16, color = 'black')\n",
    "    ax.set_xlabel('Measured magnitude', fontsize = 16, color = 'black')\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(8))\n",
    "    ax.plot((1.1,70),(1.1,8),'r--', linewidth = 3, alpha = 0.5)\n",
    "    ax.text(s = 'Testing results', x = 2, y = 8, fontsize = 18, backgroundcolor = 'lightskyblue', color = 'black')\n",
    "    ax.text(s = 'STF magnitude: ' + str(round(Mw,2)), x = 2, y = 7.5, fontsize = 18, backgroundcolor = 'lightgreen', color = 'black')\n",
    "\n",
    "    #plt.show()\n",
    "    plt.savefig(save_dir + '/boxplot_durline_' + m_name + '.png', format = 'PNG', facecolor = 'white', transparent = False)\n",
    "    plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3705089d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0581412848108464], [0.48092751398624256])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_errors, std_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8bd47a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(models_figs_path + str(dataset) + '_' + str(nsamp) + 'testsamp_' + str(training_samps) + 'trainsamp_meanerrors_c.txt', np.array(mean_errors))\n",
    "np.savetxt(models_figs_path + str(dataset) + '_' + str(nsamp) + 'testsamp_' + str(training_samps) + 'trainsamp_stderrors_c.txt', np.array(std_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_errors, std_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "14217430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### ----- Plot error and std for all windows ----- ###\n",
    "\n",
    "# shift_lengths = []\n",
    "\n",
    "# for cut_len in cut_lens:\n",
    "#     shift_len = cut_len - max_shift\n",
    "#     shift_lengths.append(shift_len)\n",
    "    \n",
    "# plt.figure(figsize = (10, 6), facecolor = 'white')\n",
    "# plt.title('Testing errors/stds: models trained with\\n100,000 augmented samples shifted up to 3 seconds', fontsize = 16)\n",
    "# plt.errorbar(shift_lengths, mean_errors, yerr = std_errors, fmt = '.', markersize = 10, ecolor = 'C1', capsize = 3, label = 'Error bars show 1 standard\\ndeviation above each point and\\n1 standard deviation below')\n",
    "# plt.scatter(shift_lengths, mean_errors, color = 'C0')\n",
    "# plt.grid()\n",
    "# plt.xlabel('Window length (s)', fontsize = 14)\n",
    "# plt.ylabel('Mean error\\n(predicted - measured magnitude)', fontsize = 14)\n",
    "# plt.xticks(fontsize = 13)\n",
    "# plt.yticks(fontsize = 13)\n",
    "# plt.legend(fontsize = 12)\n",
    "# plt.axhline(0, color = 'black', linestyle = '--', alpha = 0.75)\n",
    "\n",
    "# #plt.show()\n",
    "# plt.savefig(models_figs_path + str(dataset) + '_' + str(nsamp) + 'testsamp_' + str(training_samps) + 'trainsamp_all_errors_stds.png', format = 'PNG', facecolor = 'white', transparent = False)\n",
    "# plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f134cd92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 0.07824107041140992\n",
      "90 0.07561395617879313\n",
      "100 0.08343153847651999\n",
      "110 0.05770903766046577\n",
      "120 0.06971384641910099\n"
     ]
    }
   ],
   "source": [
    "for cl, cme in zip(cut_lens_finish, mean_errors):\n",
    "    print(cl, cme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d36f676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f996e6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
