{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "641ae5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Imports ----- ###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os.path\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from scipy import stats\n",
    "\n",
    "dataset = 'v1b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b22c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Parameters ----- ###\n",
    "\n",
    "# Where to save the products\n",
    "models_figs_path = '/home/sdybing/mlaapde/testdata_preds/all_test_rerun/figures/'\n",
    "\n",
    "# MLAAPDE/data generation params\n",
    "sr = 20 # Sampling rate\n",
    "trim_sec = 60 # Trimming amount around phase pick to get from MLAAPDE\n",
    "trim_pre_sec = trim_sec\n",
    "trim_post_sec = trim_pre_sec\n",
    "window_len = trim_pre_sec + trim_post_sec\n",
    "n_channels = 3 # Instrument channels\n",
    "cut_lens = [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 30, 35, 40, 50, 60, 70, 80, 90, 100, 110, 120]\n",
    "cut_lens_finish = [70, 80, 90, 100, 110, 120]\n",
    "cut_lens_test = [7, 8]\n",
    "desired_shift = 3\n",
    "max_shift = desired_shift * 2 # Since the shifting method actually makes it half what this value is set to\n",
    "min_snr_db = False\n",
    "max_snr_db = False\n",
    "log_progress_fraction = 100\n",
    "valid_phases = ['P', 'Pn', 'Pg']\n",
    "cast_dtype = np.float32\n",
    "\n",
    "# Training/model params\n",
    "epochs_number = 200\n",
    "batch_size = int(256) # Reducing to help memory\n",
    "monte_carlo_sampling = 50\n",
    "drop_rate = 0.5\n",
    "filters = [32, 64, 96, 128, 256] \n",
    "\n",
    "# Used if loading a trained model\n",
    "training_dataset = 'v1b'\n",
    "shift_status = 'shifted'\n",
    "model_folder_path = '/home/sdybing/mlaapde/training/'\n",
    "\n",
    "# To make end error plots\n",
    "mean_errors = []\n",
    "std_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "895208f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Load the MLAAPDE testing dataset from HDF5 files ----- ###\n",
    "\n",
    "hdf5_save_dir = '/hdd/mlaapde/decimated'\n",
    "\n",
    "testing_data = h5py.File(hdf5_save_dir + '/testing_data.hdf5', 'r')\n",
    "test_waves = testing_data['waves'][:]\n",
    "test_mags = testing_data['magnitude'][:]\n",
    "test_phase_id = testing_data['phase_id'][:]\n",
    "\n",
    "testing_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc944674",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = h5py.File(hdf5_save_dir + '/training_data_full_decimate2.hdf5', 'r')\n",
    "train_mags = train_data['magnitude'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9057f09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(train_mags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb9b2e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_mags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed679636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324365, 2400, 3)\n",
      "(324365,)\n"
     ]
    }
   ],
   "source": [
    "test_waves_t = test_waves.transpose(0,2,1)\n",
    "\n",
    "print(test_waves_t.shape)\n",
    "print(test_mags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9038a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b82d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamp = 2920609\n",
    "n_test_samp = len(test_mags)\n",
    "data = 'testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24e2aec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13449, 2400, 3)\n",
      "(13449, 2400, 3)\n",
      "(13151, 2400, 3)\n",
      "(13449,)\n",
      "(13151,)\n"
     ]
    }
   ],
   "source": [
    "### ----- Load the historic testing dataset ----- ###\n",
    "\n",
    "historic_path = '/hdd/mlaapde/decimated/'\n",
    "\n",
    "historic_test_waves = np.load(historic_path + 'historic_test_waves.npy')\n",
    "historic_test_mags = np.load(historic_path + 'historic_test_mags.npy')\n",
    "print(historic_test_waves.shape)\n",
    "n_channels_hist = 3\n",
    "\n",
    "bad_hist_indices = np.loadtxt('/home/sdybing/mlaapde/codes/bad_historic_waves.txt').astype(int)\n",
    "\n",
    "historic_test_waves_nonan = np.delete(historic_test_waves, bad_hist_indices, axis = 0)\n",
    "historic_test_mags_nonan = np.delete(historic_test_mags, bad_hist_indices, axis = 0)\n",
    "\n",
    "print(historic_test_waves.shape)\n",
    "print(historic_test_waves_nonan.shape)\n",
    "print(historic_test_mags.shape)\n",
    "print(historic_test_mags_nonan.shape)\n",
    "\n",
    "n_historic_test_samp = len(historic_test_waves_nonan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a546a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Cut len: 7\n",
      "Shift len: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 17:01:51.079431: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2023-04-13 17:01:51.079470: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: valdivia\n",
      "2023-04-13 17:01:51.079477: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: valdivia\n",
      "2023-04-13 17:01:51.079609: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.182.3\n",
      "2023-04-13 17:01:51.079637: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.161.3\n",
      "2023-04-13 17:01:51.079644: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 470.161.3 does not match DSO version 470.182.3 -- cannot find working devices in this configuration\n",
      "2023-04-13 17:01:51.079958: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.084\n",
      "Error standard deviation: 1.18\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 8\n",
      "Shift len: 2\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.062\n",
      "Error standard deviation: 1.14\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 9\n",
      "Shift len: 3\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.028\n",
      "Error standard deviation: 1.11\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 10\n",
      "Shift len: 4\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.049\n",
      "Error standard deviation: 1.05\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 11\n",
      "Shift len: 5\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.015\n",
      "Error standard deviation: 1.0\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 12\n",
      "Shift len: 6\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: -0.002\n",
      "Error standard deviation: 0.96\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 13\n",
      "Shift len: 7\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.011\n",
      "Error standard deviation: 0.92\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 14\n",
      "Shift len: 8\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: -0.003\n",
      "Error standard deviation: 0.88\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 15\n",
      "Shift len: 9\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: -0.034\n",
      "Error standard deviation: 0.86\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 16\n",
      "Shift len: 10\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: -0.006\n",
      "Error standard deviation: 0.82\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 17\n",
      "Shift len: 11\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: -0.005\n",
      "Error standard deviation: 0.8\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 19\n",
      "Shift len: 13\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.009\n",
      "Error standard deviation: 0.78\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 20\n",
      "Shift len: 14\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.001\n",
      "Error standard deviation: 0.78\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 25\n",
      "Shift len: 19\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: -0.006\n",
      "Error standard deviation: 0.73\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 30\n",
      "Shift len: 24\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.037\n",
      "Error standard deviation: 0.7\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 35\n",
      "Shift len: 29\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.031\n",
      "Error standard deviation: 0.67\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 40\n",
      "Shift len: 34\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.044\n",
      "Error standard deviation: 0.65\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 50\n",
      "Shift len: 44\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.025\n",
      "Error standard deviation: 0.62\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 60\n",
      "Shift len: 54\n",
      "Loading weights...\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 17:41:37.845248: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4374207360 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error: 0.04\n",
      "Error standard deviation: 0.61\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 70\n",
      "Shift len: 64\n",
      "Loading weights...\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 17:46:37.319097: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5184245760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error: 0.034\n",
      "Error standard deviation: 0.61\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 80\n",
      "Shift len: 74\n",
      "Loading weights...\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 17:52:24.852119: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 5994284160 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error: 0.03\n",
      "Error standard deviation: 0.58\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 90\n",
      "Shift len: 84\n",
      "Loading weights...\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 17:58:54.979687: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6804322560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error: 0.042\n",
      "Error standard deviation: 0.57\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 100\n",
      "Shift len: 94\n",
      "Loading weights...\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 18:06:07.979068: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7614360960 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error: 0.025\n",
      "Error standard deviation: 0.57\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 110\n",
      "Shift len: 104\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.02\n",
      "Error standard deviation: 0.57\n",
      "Calculating and saving bin stats...\n",
      "---------------------------------\n",
      "Cut len: 120\n",
      "Shift len: 114\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.037\n",
      "Error standard deviation: 0.55\n",
      "Calculating and saving bin stats...\n"
     ]
    }
   ],
   "source": [
    "### THE LOOP ###\n",
    "\n",
    "# Just using MLAAPDE or historic too?\n",
    "mlaa_only = False\n",
    "debug = False\n",
    "\n",
    "for cut_len in cut_lens:\n",
    "    print('---------------------------------')\n",
    "    print('Cut len: ' + str(cut_len))\n",
    "    print('Shift len: ' + str(cut_len-6))\n",
    "        \n",
    "    ### ----- MLAAPDE DATA ----- ###\n",
    "    \n",
    "    ### ----- Cut and shift testing data to match the training data ----- ###\n",
    "    ## Cut ##\n",
    "    if debug:\n",
    "        rand = np.random.choice(np.arange(0,len(test_mags),1))\n",
    "        print('Rand: ' + str(rand))\n",
    "        test_times = np.arange(0, window_len, 1/sr)\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Original test data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(test_times, test_waves_t[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(test_times, test_waves_t[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(test_times, test_waves_t[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "    \n",
    "    middle = int(test_waves_t.shape[1] / 2)\n",
    "    if debug: print('Middle: ' + str(middle))\n",
    "    test_size = int(n_test_samp)\n",
    "    if debug: print('test size: ' + str(test_size))\n",
    "    cut_test_waves_t = np.zeros((test_size, int(cut_len*sr), 3)) \n",
    "    if debug: print('Cut waves t shape: ' + str(cut_test_waves_t.shape))\n",
    "\n",
    "    for i in range(len(test_waves_t)):\n",
    "        cut_test_waves_t[i,] = test_waves_t[i, int(middle - (cut_len/2)*sr) : int(middle + (cut_len/2)*sr), 0:3]\n",
    "    if debug: print('Cut waves t shape: ' + str(cut_test_waves_t.shape))\n",
    "    if debug:\n",
    "        test_cut_times = np.arange(0, cut_len, 1/sr)\n",
    "        print('Rand: ' + str(rand))\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Cut test data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(test_cut_times, cut_test_waves_t[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(test_cut_times, cut_test_waves_t[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(test_cut_times, cut_test_waves_t[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "\n",
    "    ## Shift ##\n",
    "    shift_len = cut_len - max_shift\n",
    "    if debug: print('Shift len: ' + str(shift_len))\n",
    "    time_offset = np.random.uniform(low = 0, high = max_shift, size = test_size)\n",
    "    shift_test_waves_t = np.zeros((test_size, int(shift_len * sr), 3)) \n",
    "\n",
    "    for ii, offset in enumerate(time_offset):\n",
    "        bin_offset = int(offset * sr)\n",
    "        start_bin = bin_offset \n",
    "        end_bin = int(start_bin + shift_len * sr)\n",
    "        shift_test_waves_t[ii, :, 0] = cut_test_waves_t[ii, start_bin:end_bin, 0] \n",
    "        shift_test_waves_t[ii, :, 1] = cut_test_waves_t[ii, start_bin:end_bin, 1]\n",
    "        shift_test_waves_t[ii, :, 2] = cut_test_waves_t[ii, start_bin:end_bin, 2]\n",
    "\n",
    "    if debug: print('Shift waves t shape: ' + str(shift_test_waves_t.shape))\n",
    "    if debug:\n",
    "        test_shift_times = np.arange(0, shift_len, 1/sr)\n",
    "        print('Rand: ' + str(rand))\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Shifted test data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(test_shift_times, shift_test_waves_t[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(test_shift_times, shift_test_waves_t[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(test_shift_times, shift_test_waves_t[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "        \n",
    "    ### ----- HISTORIC DATA ----- ###\n",
    "    \n",
    "    ## Cut ##\n",
    "    if debug:\n",
    "        rand = np.random.choice(np.arange(0,len(historic_test_mags_nonan),1))\n",
    "        print('Rand: ' + str(rand))\n",
    "        historic_test_times = np.arange(0, window_len, 1/sr)\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Original historic test data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(historic_test_times, historic_test_waves_nonan[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(historic_test_times, historic_test_waves_nonan[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(historic_test_times, historic_test_waves_nonan[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "\n",
    "    middle = int(historic_test_waves_nonan.shape[1] / 2)\n",
    "    if debug: print('Middle: ' + str(middle))\n",
    "    historic_test_size = int(n_historic_test_samp)\n",
    "    if debug: print('historic test size: ' + str(historic_test_size))\n",
    "    cut_historic_test_waves_nonan = np.zeros((historic_test_size, int(cut_len*sr), 3)) \n",
    "    if debug: print('Cut waves shape: ' + str(cut_historic_test_waves_nonan.shape))\n",
    "\n",
    "    for i in range(len(historic_test_waves_nonan)):\n",
    "        cut_historic_test_waves_nonan[i,] = historic_test_waves_nonan[i, int(middle - (cut_len/2)*sr) : int(middle + (cut_len/2)*sr), 0:3]\n",
    "    if debug: print('Cut waves shape: ' + str(cut_historic_test_waves_nonan.shape))\n",
    "    if debug:\n",
    "        historic_test_cut_times = np.arange(0, cut_len, 1/sr)\n",
    "        print('Rand: ' + str(rand))\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Cut historic test data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(historic_test_cut_times, cut_historic_test_waves_nonan[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(historic_test_cut_times, cut_historic_test_waves_nonan[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(historic_test_cut_times, cut_historic_test_waves_nonan[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "\n",
    "    ## Shift ##\n",
    "    shift_len = cut_len - max_shift\n",
    "    if debug: print('Shift len: ' + str(shift_len))\n",
    "    time_offset = np.random.uniform(low = 0, high = max_shift, size = historic_test_size)\n",
    "    shift_historic_test_waves_nonan = np.zeros((historic_test_size, int(shift_len * sr), 3)) \n",
    "\n",
    "    for ii, offset in enumerate(time_offset):\n",
    "        bin_offset = int(offset * sr)\n",
    "        start_bin = bin_offset \n",
    "        end_bin = int(start_bin + shift_len * sr)\n",
    "        shift_historic_test_waves_nonan[ii, :, 0] = cut_historic_test_waves_nonan[ii, start_bin:end_bin, 0] \n",
    "        shift_historic_test_waves_nonan[ii, :, 1] = cut_historic_test_waves_nonan[ii, start_bin:end_bin, 1]\n",
    "        shift_historic_test_waves_nonan[ii, :, 2] = cut_historic_test_waves_nonan[ii, start_bin:end_bin, 2]\n",
    "\n",
    "    if debug: print('Shift waves shape: ' + str(shift_historic_test_waves_nonan.shape))\n",
    "    if debug:\n",
    "        historic_test_shift_times = np.arange(0, shift_len, 1/sr)\n",
    "        print('Rand: ' + str(rand))\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Shifted historic test data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(historic_test_shift_times, shift_historic_test_waves_nonan[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(historic_test_shift_times, shift_historic_test_waves_nonan[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(historic_test_shift_times, shift_historic_test_waves_nonan[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "\n",
    "    ### ----- Initialize the model and training setup ----- ###\n",
    "\n",
    "    inp1 = tf.keras.layers.Input(shape = (sr*(cut_len - max_shift), n_channels), name = 'input_layer') \n",
    "    e = tf.keras.layers.Conv1D(filters[1], 3, padding = 'same')(inp1) \n",
    "    e = tf.keras.layers.Dropout(drop_rate)(e, training = True)\n",
    "    e = tf.keras.layers.MaxPooling1D(4, padding = 'same')(e)\n",
    "    e = tf.keras.layers.Conv1D(filters[0], 3, padding = 'same')(e) \n",
    "    e = tf.keras.layers.Dropout(drop_rate)(e, training = True)\n",
    "    e = tf.keras.layers.MaxPooling1D(4, padding = 'same')(e)\n",
    "    e = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences = False, dropout = 0.0, recurrent_dropout = 0.0))(e)\n",
    "    e = tf.keras.layers.Dense(1)(e)\n",
    "    o = tf.keras.layers.Activation('linear', name = 'output_layer')(e)\n",
    "    model = tf.keras.models.Model(inputs = [inp1], outputs = o)\n",
    "    #model.summary()\n",
    "\n",
    "    #model.compile(optimizer = 'Adam', loss = customLoss)\n",
    "    model.compile(optimizer = 'Adam', loss = tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "    model_name = str(dataset) + '_' + str(nsamp) + 'samps_' + str(shift_len) + 's'\n",
    "    m_name = str(model_name) + '_{epoch:03d}.h5' \n",
    "    \n",
    "    ### ----- Combine the MLAAPDE and historic testing data ----- ###\n",
    "\n",
    "    all_test_waves = np.concatenate((shift_test_waves_t, shift_historic_test_waves_nonan))\n",
    "    # print(all_test_waves.shape)\n",
    "    all_test_mags = np.concatenate((test_mags, historic_test_mags_nonan))\n",
    "    # print(all_test_mags.shape)\n",
    "\n",
    "    all_test_mags = np.round_(all_test_mags, decimals = 1) # Get rid of extra digits\n",
    "\n",
    "    ### ----- What trained model are we loading? ----- ###\n",
    "    \n",
    "    model_path = model_folder_path + training_dataset + '_' + str(nsamp) + 'samps_' + str(shift_len) + 's_window/'\n",
    "    # print(model_path)\n",
    "    list_of_models = glob.glob(model_path + '*.h5') # * means all if need specific format then *.csv\n",
    "    # print(list_of_models)\n",
    "    numbers = []\n",
    "    for item in list_of_models:\n",
    "        numbers.append(item[-6:-3])\n",
    "    latest_model = model_path + training_dataset + '_' + str(nsamp) + 'samps_' + str(shift_len) + 's_' + max(numbers) + '.h5'\n",
    "    # print('Model: ' + str(latest_model))\n",
    "\n",
    "    print('Loading weights...')\n",
    "    model.load_weights(latest_model)\n",
    "    \n",
    "    ### ----- Make the predictions ----- ###\n",
    "    \n",
    "    print('Predicting...')\n",
    "    if mlaa_only == False:\n",
    "        predict_all = model.predict(all_test_waves)\n",
    "        all_test_mags = all_test_mags\n",
    "        tag = '_all_test'\n",
    "        np.save('/home/sdybing/mlaapde/testdata_preds/all_test_rerun/mag_preds/' + str(cut_len-6) + 's_window_magpreds.npy', predict_all)\n",
    "        \n",
    "    if mlaa_only == True:\n",
    "        predict_all = model.predict(shift_test_waves_t)\n",
    "        all_test_mags = test_mags\n",
    "        tag = '_mlaa_only'\n",
    "        np.save('/home/sdybing/mlaapde/testdata_preds/mlaa_only/pred_mags_' + str(cut_len-6) + 's_window.npy', predict_all)\n",
    "\n",
    "    # print(predict_all.shape)\n",
    "    \n",
    "    ## ----- Quick plot of the predictions vs. true magnitudes ----- ###\n",
    "\n",
    "    fig4, ax = plt.subplots(facecolor = 'white')\n",
    "    ax.scatter(all_test_mags, predict_all, alpha = 0.4, facecolors = 'r', edgecolors = 'r')\n",
    "    ax.plot([all_test_mags.min(), all_test_mags.max()], [all_test_mags.min(), all_test_mags.max()], 'k--', alpha=1, lw=2)\n",
    "    ax.set_xlabel('Measured magnitude')\n",
    "    ax.set_ylabel('Predicted magnitude')\n",
    "#     plt.show()\n",
    "    fig4.savefig(models_figs_path + 'scatter_plots/' + str(cut_len-6) + 's_window_scatter_pred_vs_cat.png')\n",
    "    plt.close();\n",
    "    \n",
    "    ### ----- Rename things ----- ###\n",
    "\n",
    "    measured_mags = all_test_mags\n",
    "    predicted_mags = predict_all.flatten()\n",
    "\n",
    "    ### ----- Calculate the error and standard deviation ----- ###\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    for idx in range(len(predicted_mags)):\n",
    "        predicted = predicted_mags[idx]\n",
    "        measured = measured_mags[idx]\n",
    "        error = predicted - measured\n",
    "        errors.append(error)\n",
    "        \n",
    "    mean_error = np.mean(np.array(errors))\n",
    "    std_error = np.std(np.array(errors))\n",
    "    \n",
    "    # print('Error shape: ' + str(np.array(errors).shape))\n",
    "    \n",
    "    if mlaa_only == False:\n",
    "        np.savetxt('/home/sdybing/mlaapde/testdata_preds/all_test_rerun/errors/' + str(cut_len-6) + 's_window_errors.txt', np.array(errors))\n",
    "        \n",
    "    if mlaa_only == True:\n",
    "        np.savetxt('/home/sdybing/mlaapde/testdata_preds/mlaa_only/test_errors_' + str(cut_len-6) + 's_window_errors.txt', np.array(errors))\n",
    "\n",
    "    print('Mean error: ' + str(round(mean_error,3)))\n",
    "    print('Error standard deviation: ' + str(round(std_error,2)))\n",
    "    \n",
    "#     plt.figure(figsize = (8,6), dpi = 300)\n",
    "#     plt.hist(errors, bins = 50, color = '#2DADB4')\n",
    "#     plt.title(str(shift_len) + 's window: magnitude prediction errors', fontsize = 18)\n",
    "#     plt.xlabel('Predicted - catalog magnitude', fontsize = 14)\n",
    "#     plt.ylabel('Count', fontsize = 14)\n",
    "#     plt.xticks(fontsize = 12)\n",
    "#     plt.yticks(fontsize = 12)\n",
    "#     plt.text(x = -0.055, y = 0.495, s = 'Mean: ' + str(round(mean_error,2)) + '\\nSTD: ' + str(round(std_error,2)), fontsize = 18, backgroundcolor = 'lightgray', transform = ax.transAxes)\n",
    "#     plt.savefig(save_dir + '/error_histogram_' + m_name + '.png', format = 'PNG', facecolor = 'white', transparent = False);\n",
    "#     # plt.show();\n",
    "\n",
    "    mean_errors.append(mean_error)\n",
    "    std_errors.append(std_error)\n",
    "\n",
    "    ### ----- Make the box and whisker plots with STF magnitude line ----- ###\n",
    "\n",
    "    Tt = shift_len / 2\n",
    "    M0_dyncm = Tt**3 * (0.625 * 10**23)\n",
    "    Mw = ((2/3) * np.log10(M0_dyncm)) - 10.73 # M0 in dyne-cm\n",
    "\n",
    "    # print('Rupture duration: ' + str(Tt) + ' seconds')\n",
    "    # print('M0: ' + str(M0_dyncm) + ' dyne-cm')\n",
    "    # print('Mw: ' + str(round(Mw,2)))\n",
    "\n",
    "    bins = np.arange(7,92,1)/10\n",
    "    data_bins = []\n",
    "\n",
    "    for abin in bins:\n",
    "    #     print(abin)\n",
    "        i = np.where(measured_mags == abin)[0]\n",
    "    #     print(measured_mags[i])\n",
    "        predict_bin = np.array(predicted_mags[i])\n",
    "    #     print(predict_bin)\n",
    "        data_bins.append(predict_bin)\n",
    "    #     print('-----')\n",
    "    \n",
    "    # ----- Calculate statistics for bins ----- #\n",
    "    \n",
    "    print('Calculating and saving bin stats...')\n",
    "    \n",
    "    Q1s = []\n",
    "    Q3s = []\n",
    "    IQRs = []\n",
    "    medians = []\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    for idx in range(len(data_bins)):\n",
    "        # print('-----------')\n",
    "        \n",
    "        try:\n",
    "            data = data_bins[idx]\n",
    "            # print(data)\n",
    "            Q1 = np.quantile(data, 0.25)\n",
    "            Q3 = np.quantile(data, 0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            median = np.median(data)\n",
    "            mean = np.mean(data)\n",
    "            std = np.std(data)\n",
    "\n",
    "        #     print('Q1: ' + str(Q1))\n",
    "        #     print('Q3: ' + str(Q3))\n",
    "        #     print('IQR: ' + str(IQR))\n",
    "        #     print('Median: ' + str(median))\n",
    "        #     print('Mean: ' + str(mean))\n",
    "        #     print('Standard deviation: ' + str(std))\n",
    "\n",
    "            Q1s.append(Q1)\n",
    "            Q3s.append(Q3)\n",
    "            IQRs.append(IQR)\n",
    "            medians.append(median)\n",
    "            means.append(mean)\n",
    "            stds.append(std)\n",
    "\n",
    "        except: # if bin is empty\n",
    "            Q1s.append('nan')\n",
    "            Q3s.append('nan')\n",
    "            IQRs.append('nan')\n",
    "            medians.append('nan')\n",
    "            means.append('nan')\n",
    "            stds.append('nan')\n",
    "\n",
    "    # print(len(Q1s))\n",
    "    # print(len(Q3s))\n",
    "    # print(len(IQRs))\n",
    "    # print(len(medians))\n",
    "    # print(len(means))\n",
    "    # print(len(stds))\n",
    "\n",
    "    # ----- Where to save stats ----- #\n",
    "    \n",
    "    stats_save_dir = '/home/sdybing/mlaapde/testdata_preds/all_test_rerun/boxplot_stats/' + str(cut_len-6) + 's_window/'\n",
    "    if os.path.isdir(stats_save_dir):\n",
    "        pass\n",
    "    else: # deletes directory to start over: shutil.rmtree(save_dir)  \n",
    "        os.makedirs(stats_save_dir)\n",
    "\n",
    "    np.save(stats_save_dir + str(cut_len-6) + 's_window_Q1s.npy', np.array(Q1s))\n",
    "    np.save(stats_save_dir + str(cut_len-6) + 's_window_Q3s.npy', np.array(Q3s))\n",
    "    np.save(stats_save_dir + str(cut_len-6) + 's_window_IQRs.npy', np.array(IQRs))\n",
    "    np.save(stats_save_dir + str(cut_len-6) + 's_window_medians.npy', np.array(medians))\n",
    "    np.save(stats_save_dir + str(cut_len-6) + 's_window_means.npy', np.array(means))\n",
    "    np.save(stats_save_dir + str(cut_len-6) + 's_window_stds.npy', np.array(stds))\n",
    "    \n",
    "    # ----- Make boxplot ----- #\n",
    "\n",
    "    fig = plt.figure(figsize = (14, 9), dpi = 300, facecolor = 'white')\n",
    "\n",
    "    plt.rcParams['text.usetex'] = False\n",
    "\n",
    "    fig.suptitle(str(shift_len) + 's window', fontsize = 20, y = 0.93, color = 'black')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_facecolor('white')\n",
    "    # ax.text(x = 30, y = 8.8, s = 'Model: ' + m_name, fontsize = 13, color = 'black')\n",
    "    ax.grid(which = 'major', axis = 'y', markevery = 0.5, zorder = 2)\n",
    "    ax.grid(which = 'major', axis = 'x', zorder = 2.5)\n",
    "    ax.set_ylim(0,9.2)\n",
    "\n",
    "    bp = ax.boxplot(data_bins, notch = False, patch_artist = True, zorder = 3)\n",
    "\n",
    "    both_test_mags = [test_mags*10-6, historic_test_mags_nonan*10-6]\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.hist(both_test_mags, bins = 85, color = ['#730114', '#f01f42'], stacked = True, zorder = 3.5)\n",
    "    ax2.set_ylim(0,110000)\n",
    "    ax2.set_yticks([0, 10000, 20000])\n",
    "    ax2.set_yticklabels(['0', '10,000', '20,000'], style = 'italic')\n",
    "    # ax2.set_ylabel('Count of waveforms in each magnitude bin', fontsize = 16, color = 'black', rotation = 270, labelpad = 18)\n",
    "    ax2.text(s = 'Count of waveforms\\nin each magnitude bin', x = 86.5, y = 26000, fontsize = 16, color = 'black', rotation = 270, style = 'italic')\n",
    "    ax2.tick_params(labelsize = 14, color = 'black')\n",
    "    ax2.set_zorder(3.5)\n",
    "\n",
    "    ax2.axvline(((Mw*10)-6), color = 'blue', linestyle = '--', linewidth = 2, zorder = 20)\n",
    "\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor('#72d1d6')\n",
    "        patch.set_edgecolor('#001528')\n",
    "    for median in bp['medians']:\n",
    "        median.set(color = '#001528', linewidth = 3)\n",
    "    for whisker in bp['whiskers']:\n",
    "        whisker.set(color = '#001528', linewidth = 1)\n",
    "    for cap in bp['caps']:\n",
    "        cap.set(color = '#001528', linewidth = 1)\n",
    "    for flier in bp['fliers']:\n",
    "        flier.set(marker = '+', color = '#001528', alpha = 0.5)\n",
    "\n",
    "    bins_list = bins.tolist()\n",
    "    ax.set_xticklabels(bins_list, fontsize = 14, color = 'black')\n",
    "    ax.xaxis.set_major_locator(ticker.FixedLocator([4, 14, 24, 34, 44, 54, 64, 74, 84]))\n",
    "    ax.set_yticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    ax.tick_params(labelsize = 14, color = 'black')\n",
    "    ax.set_ylabel('Predicted magnitude', fontsize = 16, color = 'black')\n",
    "    ax.set_xlabel('Catalog magnitude', fontsize = 16, color = 'black')\n",
    "\n",
    "    linex = [4, 14, 24, 34, 44, 54, 64, 74, 84]\n",
    "    liney = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    liney05u = [1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n",
    "    liney05d = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5]\n",
    "\n",
    "    ax.plot(linex, liney, 'black', linestyle = '--', linewidth = 3, alpha = 0.4)\n",
    "    ax.plot(linex, liney05u, 'gray', linestyle = '--', linewidth = 2, alpha = 0.4)\n",
    "    ax.plot(linex, liney05d, 'gray', linestyle = '--', linewidth = 2, alpha = 0.4)\n",
    "    ax2.text(s = 'Testing data results', x = 2, y = 104000, fontsize = 18, backgroundcolor = '#72d1d6', color = 'black', zorder = 25)\n",
    "    ax2.text(s = 'STF magnitude: ' + str(round(Mw,2)), x = 2, y = 96500, fontsize = 18, backgroundcolor = 'blue', color = 'white', zorder = 25)\n",
    "    ax2.text(s = 'MLAAPDE test data distrib.', x = 57.8, y = 20000, fontsize = 18, backgroundcolor = '#730114', color = 'white', zorder = 25)\n",
    "    ax2.text(s = 'Historic test data distrib.', x = 59.85, y = 12500, fontsize = 18, backgroundcolor = '#f01f42', color = 'white', zorder = 25)\n",
    "\n",
    "#     plt.show();\n",
    "#     plt.savefig(save_dir + '/boxplot_durline_' + m_name + '.png', format = 'PNG', facecolor = 'white', transparent = False)\n",
    "#     plt.savefig('/home/sdybing/mlaapde/figures/testing/boxplots/' + str(cut_len-6) + 's_window.png', format = 'PNG', facecolor = 'white', transparent = False)\n",
    "    plt.savefig(models_figs_path + 'boxplots/' + str(cut_len-6) + 's_window_boxplot_pred_vs_cat.png', format = 'PNG', facecolor = 'white', transparent = False)\n",
    "    plt.close();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "757f1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('/home/sdybing/mlaapde/testdata_preds/all_test_rerun/meanerrors.txt', np.array(mean_errors))\n",
    "np.savetxt('/home/sdybing/mlaapde/testdata_preds/all_test_rerun/stderrors.txt', np.array(std_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f54cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Plot error and std for all windows ----- ###\n",
    "\n",
    "shift_lengths = []\n",
    "\n",
    "for cut_len in cut_lens:\n",
    "    shift_len = cut_len - max_shift\n",
    "    shift_lengths.append(shift_len)\n",
    "    \n",
    "plt.figure(figsize = (10, 6), dpi = 300, facecolor = 'white')\n",
    "plt.title('Testing errors/stds: models trained with\\n2.92 million augmented samples shifted up to 3 seconds', fontsize = 16)\n",
    "plt.errorbar(shift_lengths, mean_errors, color = '#001528', yerr = std_errors, fmt = '.', markersize = 10, ecolor = '#f01f42', capsize = 3, label = 'Error bars show 1 standard\\ndeviation above each point and\\n1 standard deviation below')\n",
    "# plt.scatter(shift_lengths, mean_errors, color = '#2DADB4')\n",
    "plt.grid()\n",
    "plt.xlabel('Window length (s)', fontsize = 14)\n",
    "plt.ylabel('Mean error\\n(Predicted - catalog magnitude)', fontsize = 14)\n",
    "plt.xticks(fontsize = 13)\n",
    "plt.yticks(fontsize = 13)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.axhline(0, color = 'black', linestyle = '--', alpha = 0.75)\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig('/home/sdybing/mlaapde/testdata_preds/all_test_rerun/meanstderror_timeplot.png', format = 'PNG', facecolor = 'white', transparent = False)\n",
    "plt.close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
