{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641ae5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Imports ----- ###\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/home/sdybing/neic-mlaapde')\n",
    "\n",
    "# from mlaapde.access import MLAAPDE_Access\n",
    "# from mlaapde import UTC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "\n",
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "\n",
    "# mlpa = MLAAPDE_Access(data_dir = '/data/hank/mlaapde_subset/data', random_seed = 616) # 3 months\n",
    "# dataset = 'subset'\n",
    "\n",
    "# mlpa = MLAAPDE_Access(data_dir = '/data/hank/mlaapde_v1b/data', random_seed = 616)\n",
    "dataset = 'v1b'\n",
    "\n",
    "# mlpa.data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af6430b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#         logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#         print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "#         raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b22c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Parameters ----- ###\n",
    "\n",
    "# Where to save the products\n",
    "models_figs_path = '/home/sdybing/mlaapde/figures/'\n",
    "\n",
    "# MLAAPDE/data generation params\n",
    "#nsamp = False # Samples of waveforms to load from MLAAPDE\n",
    "#n_train_samp = 1000000\n",
    "#n_valid_samp = 200000\n",
    "#nsamp = n_train_samp + n_valid_samp\n",
    "sr = 40 # Sampling rate\n",
    "trim_sec = 60 # Trimming amount around phase pick to get from MLAAPDE\n",
    "trim_pre_sec = trim_sec\n",
    "trim_post_sec = trim_pre_sec\n",
    "window_len = trim_pre_sec + trim_post_sec\n",
    "#train_split = 0.8 # Percentage of data used in training\n",
    "#valid_split = 0.2 # Percentage of data used for validation\n",
    "n_channels = 3 # Instrument channels\n",
    "cut_lens = [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 30, 35, 40, 50, 60, 70, 80, 90, 100, 110, 120]\n",
    "cut_lens_finish = [70, 80, 90, 100, 110, 120]\n",
    "cut_lens_test = [7, 8]\n",
    "desired_shift = 3\n",
    "max_shift = desired_shift * 2 # Since the shifting method actually makes it half what this value is set to\n",
    "min_snr_db = False\n",
    "max_snr_db = False\n",
    "log_progress_fraction = 100\n",
    "valid_phases = ['P', 'Pn', 'Pg']\n",
    "cast_dtype = np.float32\n",
    "\n",
    "# Training/model params\n",
    "epochs_number = 200\n",
    "batch_size = int(256) # Reducing to help memory\n",
    "monte_carlo_sampling = 50\n",
    "drop_rate = 0.5\n",
    "filters = [32, 64, 96, 128, 256] \n",
    "\n",
    "# Used if loading a trained model\n",
    "training_dataset = 'v1b'\n",
    "shift_status = 'shifted'\n",
    "model_folder_path = '/home/sdybing/mlaapde/training/'\n",
    "\n",
    "# To make end error plots\n",
    "mean_errors = []\n",
    "std_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db208001",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_save_dir = '/hdd/mlaapde'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895208f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['magnitude', 'magnitude_type', 'phase_id', 'snr_db', 'waves']\n"
     ]
    }
   ],
   "source": [
    "### ----- Load the full dataset from HDF5 files ----- ###\n",
    "\n",
    "training_data = h5py.File(hdf5_save_dir + '/training_data.hdf5', 'r')\n",
    "dataset_names = list(training_data.keys())\n",
    "print(dataset_names)\n",
    "\n",
    "train_waves = training_data['waves'][:]\n",
    "train_mags = training_data['magnitude'][:]\n",
    "train_phase_id = training_data['phase_id'][:]\n",
    "\n",
    "validation_data = h5py.File(hdf5_save_dir + '/validation_data.hdf5', 'r')\n",
    "valid_waves = validation_data['waves'][:]\n",
    "valid_mags = validation_data['magnitude'][:]\n",
    "valid_phase_id = training_data['phase_id'][:]\n",
    "\n",
    "# testing_data = h5py.File(hdf5_save_dir + '/testing_data.hdf5', 'r')\n",
    "# test_waves = testing_data['waves'][:]\n",
    "# test_mags = testing_data['magnitude'][:]\n",
    "# test_phase_id = testing_data['phase_id'][:]\n",
    "\n",
    "training_data.close()\n",
    "validation_data.close()\n",
    "# testing_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1708294e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2431341, 3, 4800)\n",
      "(2431341,)\n",
      "(489268, 3, 4800)\n",
      "(489268,)\n"
     ]
    }
   ],
   "source": [
    "print(train_waves.shape)\n",
    "print(train_mags.shape)\n",
    "print(valid_waves.shape)\n",
    "print(valid_mags.shape)\n",
    "# print(test_waves.shape)\n",
    "# print(test_mags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed679636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2431341, 4800, 3)\n",
      "(2431341,)\n",
      "(489268, 4800, 3)\n",
      "(489268,)\n"
     ]
    }
   ],
   "source": [
    "train_waves_t = train_waves.transpose(0,2,1)\n",
    "valid_waves_t = valid_waves.transpose(0,2,1)\n",
    "# test_waves_t = valid_waves.transpose(0,2,1)\n",
    "\n",
    "print(train_waves_t.shape)\n",
    "print(train_mags.shape)\n",
    "print(valid_waves_t.shape)\n",
    "print(valid_mags.shape)\n",
    "# print(test_waves_t.shape)\n",
    "# print(test_mags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9038a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_waves\n",
    "del valid_waves\n",
    "# del test_waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1828e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isfinite = np.isfinite(train_waves_t)\n",
    "# #print(isfinite)\n",
    "# i = np.where(isfinite == False)[0]\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d76dfbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = np.unique(i)\n",
    "# print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee02911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 741100\n",
    "idx2 = 741102\n",
    "# print(train_waves_t[idx])\n",
    "# print(train_waves_t[idx2])\n",
    "# plt.plot(train_waves_t[idx])\n",
    "# plt.show()\n",
    "# plt.plot(train_waves_t[idx2])\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "330b38f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us20002njs_CI.BAR.BH*.--_P\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " ...\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "us20002njs_CI.MWC.BH*.--_P\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " ...\n",
      " [nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "# Fixing the weird nan wave\n",
    "\n",
    "print(train_phase_id[idx])\n",
    "print(train_waves_t[idx])\n",
    "print(train_phase_id[idx2])\n",
    "print(train_waves_t[idx2])\n",
    "\n",
    "copy_wave = train_waves_t[0]\n",
    "copy_mag = train_mags[0]\n",
    "copy_wave2 = train_waves_t[1]\n",
    "copy_mag2 = train_mags[1]\n",
    "\n",
    "train_waves_t[idx] = copy_wave\n",
    "train_mags[idx] = copy_mag\n",
    "train_waves_t[idx2] = copy_wave2\n",
    "train_mags[idx2] = copy_mag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "710c4d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13537762 -0.07492092 -0.01111916]\n",
      " [ 0.14131626 -0.07153969 -0.02545009]\n",
      " [ 0.14370808 -0.06007923 -0.0382474 ]\n",
      " ...\n",
      " [ 0.06729667 -0.47734734 -0.44188842]\n",
      " [ 0.0809005  -0.47435188 -0.44014212]\n",
      " [ 0.07301358 -0.42699108 -0.44291207]]\n",
      "4.1\n",
      "4.1\n",
      "[[-0.15383083 -0.07718702  0.07553101]\n",
      " [-0.16129185  0.03450812  0.13697691]\n",
      " [-0.1270593   0.10472912  0.11481622]\n",
      " ...\n",
      " [-0.18223436  0.15392898 -0.21175863]\n",
      " [-0.13242158  0.12540203 -0.03071801]\n",
      " [-0.04486514  0.09270573  0.1601974 ]]\n",
      "4.1\n",
      "4.1\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure it's good now\n",
    "\n",
    "print(train_waves_t[idx])\n",
    "print(train_mags[idx])\n",
    "print(train_mags[0])\n",
    "\n",
    "print(train_waves_t[idx2])\n",
    "print(train_mags[idx2])\n",
    "print(train_mags[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b82d944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2920609\n"
     ]
    }
   ],
   "source": [
    "n_train_samp = len(train_mags)\n",
    "n_valid_samp = len(valid_mags)\n",
    "nsamp = n_train_samp + n_valid_samp\n",
    "print(nsamp)\n",
    "data = 'validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1746f6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut len: 7\n",
      "Model: /home/sdybing/mlaapde/training/v1b_2920609samps_7s_window/v1b_2920609samps_7s_033.h5\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: -2.041\n",
      "Error standard deviation: 1.05\n",
      "Rupture duration: 0.5 seconds\n",
      "M0: 7.8125e+21 dyne-cm\n",
      "Mw: 3.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-ea23fbc32ef3>:231: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([1, 2, 3, 4, 5, 6, 7, 8], fontsize = 14, color = 'black')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut len: 8\n",
      "Model: /home/sdybing/mlaapde/training/v1b_2920609samps_8s_window/v1b_2920609samps_8s_010.h5\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: -0.93\n",
      "Error standard deviation: 1.06\n",
      "Rupture duration: 1.0 seconds\n",
      "M0: 6.25e+22 dyne-cm\n",
      "Mw: 4.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-ea23fbc32ef3>:231: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([1, 2, 3, 4, 5, 6, 7, 8], fontsize = 14, color = 'black')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut len: 9\n",
      "Model: /home/sdybing/mlaapde/training/v1b_2920609samps_9s_window/v1b_2920609samps_9s_011.h5\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.165\n",
      "Error standard deviation: 1.02\n",
      "Rupture duration: 1.5 seconds\n",
      "M0: 2.109375e+23 dyne-cm\n",
      "Mw: 4.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-ea23fbc32ef3>:231: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([1, 2, 3, 4, 5, 6, 7, 8], fontsize = 14, color = 'black')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut len: 10\n",
      "Model: /home/sdybing/mlaapde/training/v1b_2920609samps_10s_window/v1b_2920609samps_10s_025.h5\n",
      "Loading weights...\n",
      "Predicting...\n",
      "Mean error: 0.3\n",
      "Error standard deviation: 0.96\n",
      "Rupture duration: 2.0 seconds\n",
      "M0: 5e+23 dyne-cm\n",
      "Mw: 5.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-ea23fbc32ef3>:231: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([1, 2, 3, 4, 5, 6, 7, 8], fontsize = 14, color = 'black')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut len: 11\n",
      "Model: /home/sdybing/mlaapde/training/v1b_2920609samps_11s_window/v1b_2920609samps_11s_024.h5\n",
      "Loading weights...\n",
      "Predicting...\n"
     ]
    }
   ],
   "source": [
    "########## STUFF THAT NEEDS LOOPING ##########\n",
    "\n",
    "debug = False\n",
    "\n",
    "for cut_len in cut_lens:\n",
    "    print('Cut len: ' + str(cut_len))\n",
    "    \n",
    "    ### ----- Where are the trained models/figures getting saved? ----- ###\n",
    "\n",
    "    save_dir = models_figs_path + data + '/' + str(dataset) + '_' + str(nsamp) + 'samps_' + str(cut_len-6) + 's_window'\n",
    "    if os.path.isdir(save_dir):\n",
    "        pass\n",
    "    else: # deletes directory to start over: shutil.rmtree(save_dir)  \n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    ### ----- Cut and shift validation data to match the training data ----- ###\n",
    "\n",
    "    ## Cut ##\n",
    "    if debug:\n",
    "        rand = np.random.choice(np.arange(0,len(valid_mags),1))\n",
    "        print('Rand: ' + str(rand))\n",
    "        valid_times = np.arange(0, window_len, 1/sr)\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Original validation data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(valid_times, valid_waves_t[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(valid_times, valid_waves_t[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(valid_times, valid_waves_t[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "    \n",
    "    middle = int(valid_waves_t.shape[1] / 2)\n",
    "    if debug: print('Middle: ' + str(middle))\n",
    "    valid_size = int(n_valid_samp)\n",
    "    if debug: print('Valid size: ' + str(valid_size))\n",
    "    cut_valid_waves_t = np.zeros((valid_size, int(cut_len*sr), 3)) \n",
    "    if debug: print('Cut waves t shape: ' + str(cut_valid_waves_t.shape))\n",
    "\n",
    "    for i in range(len(valid_waves_t)):\n",
    "        cut_valid_waves_t[i,] = valid_waves_t[i, int(middle - (cut_len/2)*sr) : int(middle + (cut_len/2)*sr), 0:3]\n",
    "    if debug: print('Cut waves t shape: ' + str(cut_valid_waves_t.shape))\n",
    "    if debug:\n",
    "        valid_cut_times = np.arange(0, cut_len, 1/sr)\n",
    "        print('Rand: ' + str(rand))\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Cut validation data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(valid_cut_times, cut_valid_waves_t[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(valid_cut_times, cut_valid_waves_t[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(valid_cut_times, cut_valid_waves_t[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "\n",
    "    ## Shift ##\n",
    "    shift_len = cut_len - max_shift\n",
    "    if debug: print('Shift len: ' + str(shift_len))\n",
    "    time_offset = np.random.uniform(low = 0, high = max_shift, size = valid_size)\n",
    "    shift_valid_waves_t = np.zeros((valid_size, int(shift_len * sr), 3)) \n",
    "\n",
    "    for ii, offset in enumerate(time_offset):\n",
    "        bin_offset = int(offset * sr)\n",
    "        start_bin = bin_offset \n",
    "        end_bin = int(start_bin + shift_len * sr)\n",
    "        shift_valid_waves_t[ii, :, 0] = cut_valid_waves_t[ii, start_bin:end_bin, 0] \n",
    "        shift_valid_waves_t[ii, :, 1] = cut_valid_waves_t[ii, start_bin:end_bin, 1]\n",
    "        shift_valid_waves_t[ii, :, 2] = cut_valid_waves_t[ii, start_bin:end_bin, 2]\n",
    "\n",
    "    if debug: print('Shift waves t shape: ' + str(shift_valid_waves_t.shape))\n",
    "    if debug:\n",
    "        valid_shift_times = np.arange(0, shift_len, 1/sr)\n",
    "        print('Rand: ' + str(rand))\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Shifted validation data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(valid_shift_times, shift_valid_waves_t[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(valid_shift_times, shift_valid_waves_t[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(valid_shift_times, shift_valid_waves_t[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "\n",
    "    ### ----- Initialize the model and training setup ----- ###\n",
    "    \n",
    "    inp1 = tf.keras.layers.Input(shape = ((cut_len - max_shift)*sr, n_channels), name = 'input_layer') \n",
    "    e = tf.keras.layers.Conv1D(filters[1], 3, padding = 'same')(inp1) \n",
    "    e = tf.keras.layers.Dropout(drop_rate)(e, training = True)\n",
    "    e = tf.keras.layers.MaxPooling1D(4, padding = 'same')(e)\n",
    "    e = tf.keras.layers.Conv1D(filters[0], 3, padding = 'same')(e) \n",
    "    e = tf.keras.layers.Dropout(drop_rate)(e, training = True)\n",
    "    e = tf.keras.layers.MaxPooling1D(4, padding = 'same')(e)\n",
    "    e = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences = False, dropout = 0.0, recurrent_dropout = 0.0))(e)\n",
    "    #e = tf.keras.layers.Dense(2)(e)\n",
    "    e = tf.keras.layers.Dense(1)(e)\n",
    "    o = tf.keras.layers.Activation('linear', name = 'output_layer')(e)\n",
    "    model = tf.keras.models.Model(inputs = [inp1], outputs = o)\n",
    "    #model.summary()\n",
    "\n",
    "    #model.compile(optimizer = 'Adam', loss = customLoss)\n",
    "    model.compile(optimizer = 'Adam', loss = tf.keras.losses.MeanSquaredError())\n",
    "    \n",
    "    model_name = str(dataset) + '_' + str(nsamp) + 'samps_' + str(shift_len) + 's'\n",
    "#     lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor = np.sqrt(0.1), cooldown = 0, patience = 4, min_lr = 0.5e-6)\n",
    "    m_name = str(model_name) + '_{epoch:03d}.h5' \n",
    "#     filepath = os.path.join(save_dir, m_name)\n",
    "#     early_stopping_monitor = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5)\n",
    "#     checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = filepath, monitor = 'val_loss', mode = 'auto', verbose = 1, save_best_only = True)\n",
    "#     psv = PrintSomeValues()\n",
    "#     callbacks = [lr_reducer, early_stopping_monitor, checkpoint, psv]\n",
    "#     training_generator = dataGenerator(train_waves_t, train_mags, n_train_samp, window_len, cut_len, max_shift, sr, batch_size, n_channels)\n",
    "\n",
    "#     ### ----- Train ----- ###\n",
    "\n",
    "#     history = model.fit(training_generator, epochs = epochs_number, validation_data = (shift_valid_waves_t, valid_mags), callbacks = callbacks);\n",
    "\n",
    "#     ### ----- Plot training curves ----- ###\n",
    "\n",
    "#     plt.figure(facecolor = 'white')\n",
    "#     plt.plot(history.history['loss'],label='Training Loss')\n",
    "#     plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "#     plt.legend()\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Loss')\n",
    "#     #plt.show()\n",
    "#     plt.savefig(save_dir + '/loss_curves_' + m_name + '.png')\n",
    "#     plt.close();\n",
    "    \n",
    "    ### ----- Load trained model ----- ###\n",
    "    \n",
    "    model_path = model_folder_path + training_dataset + '_' + str(nsamp) + 'samps_' + str(cut_len) + 's_window/'\n",
    "#     print(model_path)\n",
    "    list_of_models = glob.glob(model_path + '*.h5') # * means all if need specific format then *.csv\n",
    "#     print(list_of_models)\n",
    "    latest_model = max(list_of_models, key = os.path.getctime)\n",
    "    print('Model: ' + str(latest_model))\n",
    "    print('Loading weights...')\n",
    "    \n",
    "    model.load_weights(latest_model)\n",
    "\n",
    "    ### ----- Make the predictions ----- ###\n",
    "\n",
    "    #kdp = KerasDropoutPrediction(model)\n",
    "    #predict, al_unc, ep_unc, comb = kdp.predict(shift_valid_waves_t, monte_carlo_sampling)\n",
    "    print('Predicting...')\n",
    "    predict = model.predict(shift_valid_waves_t)\n",
    "\n",
    "    ### ----- Quick plot of the predictions vs. true magnitudes ----- ###\n",
    "\n",
    "    fig4, ax = plt.subplots(facecolor = 'white')\n",
    "    ax.scatter(valid_mags, predict, alpha = 0.4, facecolors = 'r', edgecolors = 'r')\n",
    "    ax.plot([valid_mags.min(), valid_mags.max()], [valid_mags.min(), valid_mags.max()], 'k--', alpha=1, lw=2)\n",
    "    ax.set_xlabel('Measured magnitude')\n",
    "    ax.set_ylabel('Predicted magnitude')\n",
    "#     plt.show()\n",
    "    fig4.savefig(save_dir + '/scatter_' + m_name + '.png')\n",
    "    plt.close();\n",
    "\n",
    "    ### ----- Rename things ----- ###\n",
    "\n",
    "    measured_mags = valid_mags\n",
    "    predicted_mags = predict.flatten()\n",
    "\n",
    "    ### ----- Calculate the error and standard deviation ----- ###\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    for idx in range(len(predicted_mags)):\n",
    "        predicted = predicted_mags[idx]\n",
    "        measured = measured_mags[idx]\n",
    "        error = predicted - measured\n",
    "        errors.append(error)\n",
    "\n",
    "    mean_error = np.mean(np.array(errors))\n",
    "    std_error = np.std(np.array(errors))\n",
    "\n",
    "    print('Mean error: ' + str(round(mean_error,3)))\n",
    "    print('Error standard deviation: ' + str(round(std_error,2)))\n",
    "\n",
    "    mean_errors.append(mean_error)\n",
    "    std_errors.append(std_error)\n",
    "\n",
    "    ### ----- Make the box and whisker plots with STF magnitude line ----- ###\n",
    "\n",
    "    Tt = shift_len / 2\n",
    "    M0_dyncm = Tt**3 * (0.625 * 10**23)\n",
    "    Mw = ((2/3) * np.log10(M0_dyncm)) - 10.73 # M0 in dyne-cm\n",
    "\n",
    "    print('Rupture duration: ' + str(Tt) + ' seconds')\n",
    "    print('M0: ' + str(M0_dyncm) + ' dyne-cm')\n",
    "    print('Mw: ' + str(round(Mw,2)))\n",
    "\n",
    "    bins = np.arange(11,85,1)/10\n",
    "    data_bins = []\n",
    "\n",
    "    for abin in bins:\n",
    "        i = np.where(valid_mags == abin)[0]\n",
    "        predict_bin = np.array(predicted_mags[i])\n",
    "        data_bins.append(predict_bin)\n",
    "\n",
    "    fig = plt.figure(figsize =(14, 9), dpi = 300, facecolor = 'white')\n",
    "\n",
    "    fig.suptitle('MLAAPDE ' + str(dataset) + ' agumented dataset, tested with ' + str(int(n_valid_samp)) + ' ' + str(shift_len) + 's window samples shifted up to 3s', fontsize = 18, y = 0.96, color = 'black')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.text(x = 30, y = 8.8, s = 'Model: ' + m_name, fontsize = 13, color = 'black')\n",
    "    ax.grid(which = 'major', axis = 'y')\n",
    "    ax.grid(which = 'major', axis = 'x', markevery = [10,20,30,40,50])\n",
    "    ax.set_ylim(1,8.6)\n",
    "\n",
    "    bp = ax.boxplot(data_bins, notch = False, patch_artist = True)\n",
    "    ax.axvline((Mw-1)*10, color = 'green', linestyle = '--', linewidth = 2) # Position = (magnitude - 1)*10\n",
    "\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor('lightblue')\n",
    "        patch.set_edgecolor('blue')\n",
    "    for median in bp['medians']:\n",
    "        median.set(color ='blue', linewidth = 3)\n",
    "    for whisker in bp['whiskers']:\n",
    "        whisker.set(color ='blue', linewidth = 1)\n",
    "    for cap in bp['caps']:\n",
    "        cap.set(color ='blue', linewidth = 1)\n",
    "    for flier in bp['fliers']:\n",
    "        flier.set(marker ='+', color ='blue', alpha = 0.5)\n",
    "\n",
    "    bins_list = bins.tolist()\n",
    "    ax.set_xticklabels(bins_list, fontsize = 14, color = 'black')\n",
    "    ax.set_yticklabels([1, 2, 3, 4, 5, 6, 7, 8], fontsize = 14, color = 'black')\n",
    "    ax.set_ylabel('Predicted magnitude', fontsize = 16, color = 'black')\n",
    "    ax.set_xlabel('Measured magnitude', fontsize = 16, color = 'black')\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(8))\n",
    "    ax.plot((1.1,70),(1.1,8),'r--', linewidth = 3, alpha = 0.5)\n",
    "    ax.text(s = 'Testing results', x = 2, y = 8, fontsize = 18, backgroundcolor = 'lightskyblue', color = 'black')\n",
    "    ax.text(s = 'STF magnitude: ' + str(round(Mw,2)), x = 2, y = 7.5, fontsize = 18, backgroundcolor = 'lightgreen', color = 'black')\n",
    "\n",
    "#     plt.show()\n",
    "    plt.savefig(save_dir + '/boxplot_durline_' + m_name + '.png', format = 'PNG', facecolor = 'white', transparent = False)\n",
    "    plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c87f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(models_figs_path + data + '/fulldataset_validsamp_meanerrors.txt', np.array(mean_errors))\n",
    "np.savetxt(models_figs_path + data + '/fulldataset_validsamp_stderrors.txt', np.array(std_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91493162",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Plot error and std for all windows ----- ###\n",
    "\n",
    "shift_lengths = []\n",
    "\n",
    "for cut_len in cut_lens:\n",
    "    shift_len = cut_len - max_shift\n",
    "    shift_lengths.append(shift_len)\n",
    "    \n",
    "plt.figure(figsize = (10, 6), facecolor = 'white')\n",
    "plt.title('Testing errors/stds: models trained with\\n100,000 augmented samples shifted up to 3 seconds', fontsize = 16)\n",
    "plt.errorbar(shift_lengths, mean_errors, yerr = std_errors, fmt = '.', markersize = 10, ecolor = 'C1', capsize = 3, label = 'Error bars show 1 standard\\ndeviation above each point and\\n1 standard deviation below')\n",
    "plt.scatter(shift_lengths, mean_errors, color = 'C0')\n",
    "plt.grid()\n",
    "plt.xlabel('Window length (s)', fontsize = 14)\n",
    "plt.ylabel('Mean error\\n(predicted - measured magnitude)', fontsize = 14)\n",
    "plt.xticks(fontsize = 13)\n",
    "plt.yticks(fontsize = 13)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.axhline(0, color = 'black', linestyle = '--', alpha = 0.75)\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(models_figs_path + data + '/fulldataset_validsamp_all_errors_stds.png', format = 'PNG', facecolor = 'white', transparent = False)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02697351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
