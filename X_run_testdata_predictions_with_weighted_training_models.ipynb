{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641ae5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 14:45:41.058016: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-16 14:45:41.058036: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "### ----- Imports ----- ###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os.path\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from scipy import stats\n",
    "\n",
    "dataset = 'v1b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b22c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Parameters ----- ###\n",
    "\n",
    "# Where to save the products\n",
    "models_figs_path = '/home/sdybing/mlaapde/testdata_preds/weighted_training/figures/'\n",
    "\n",
    "# MLAAPDE/data generation params\n",
    "sr = 20 # Sampling rate\n",
    "trim_sec = 60 # Trimming amount around phase pick to get from MLAAPDE\n",
    "trim_pre_sec = trim_sec\n",
    "trim_post_sec = trim_pre_sec\n",
    "window_len = trim_pre_sec + trim_post_sec\n",
    "n_channels = 3 # Instrument channels\n",
    "cut_lens = [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 30, 35, 40, 50, 60, 70, 80, 90, 100, 110, 120]\n",
    "weighted_cut_lens = [7, 10, 15, 20, 25, 30, 40, 50, 60, 80, 100, 120]\n",
    "weighted_cut_lens_test = [7]\n",
    "weighted_h5nums = ['018', '014', '023', '041', '034', '045', '036', '031', '027', '034', '050', '055']\n",
    "cut_lens_finish = [70, 80, 90, 100, 110, 120]\n",
    "cut_lens_test = [120]\n",
    "desired_shift = 3\n",
    "max_shift = desired_shift * 2 # Since the shifting method actually makes it half what this value is set to\n",
    "min_snr_db = False\n",
    "max_snr_db = False\n",
    "log_progress_fraction = 100\n",
    "valid_phases = ['P', 'Pn', 'Pg']\n",
    "cast_dtype = np.float32\n",
    "\n",
    "# Training/model params\n",
    "epochs_number = 200\n",
    "batch_size = int(256) # Reducing to help memory\n",
    "monte_carlo_sampling = 50\n",
    "drop_rate = 0.5\n",
    "filters = [32, 64, 96, 128, 256] \n",
    "\n",
    "# Used if loading a trained model\n",
    "training_dataset = 'v1b'\n",
    "shift_status = 'shifted'\n",
    "model_folder_path = '/home/sdybing/mlaapde/training/weighted_training/'\n",
    "\n",
    "# To make end error plots\n",
    "mean_errors = []\n",
    "std_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895208f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m hdf5_save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/hdd/mlaapde/decimated\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m testing_data \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(hdf5_save_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/testing_data.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m test_waves \u001b[38;5;241m=\u001b[39m \u001b[43mtesting_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwaves\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m test_mags \u001b[38;5;241m=\u001b[39m testing_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmagnitude\u001b[39m\u001b[38;5;124m'\u001b[39m][:]\n\u001b[1;32m      8\u001b[0m test_phase_id \u001b[38;5;241m=\u001b[39m testing_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphase_id\u001b[39m\u001b[38;5;124m'\u001b[39m][:]\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py:768\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### ----- Load the MLAAPDE testing dataset from HDF5 files ----- ###\n",
    "\n",
    "hdf5_save_dir = '/hdd/mlaapde/decimated'\n",
    "\n",
    "testing_data = h5py.File(hdf5_save_dir + '/testing_data.hdf5', 'r')\n",
    "test_waves = testing_data['waves'][:]\n",
    "test_mags = testing_data['magnitude'][:]\n",
    "test_phase_id = testing_data['phase_id'][:]\n",
    "\n",
    "testing_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc944674",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = h5py.File(hdf5_save_dir + '/training_data_full_decimate2.hdf5', 'r')\n",
    "train_mags = train_data['magnitude'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9057f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(train_mags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b2e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(train_mags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed679636",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_waves_t = test_waves.transpose(0,2,1)\n",
    "\n",
    "print(test_waves_t.shape)\n",
    "print(test_mags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamp = 2920609\n",
    "n_test_samp = len(test_mags)\n",
    "data = 'testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e2aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Load the historic testing dataset ----- ###\n",
    "\n",
    "historic_path = '/hdd/mlaapde/decimated/'\n",
    "\n",
    "historic_test_waves = np.load(historic_path + 'historic_test_waves.npy')\n",
    "historic_test_mags = np.load(historic_path + 'historic_test_mags.npy')\n",
    "print(historic_test_waves.shape)\n",
    "n_channels_hist = 3\n",
    "\n",
    "bad_hist_indices = np.loadtxt('/home/sdybing/mlaapde/codes/bad_historic_waves.txt').astype(int)\n",
    "\n",
    "historic_test_waves_nonan = np.delete(historic_test_waves, bad_hist_indices, axis = 0)\n",
    "historic_test_mags_nonan = np.delete(historic_test_mags, bad_hist_indices, axis = 0)\n",
    "\n",
    "print(historic_test_waves.shape)\n",
    "print(historic_test_waves_nonan.shape)\n",
    "print(historic_test_mags.shape)\n",
    "print(historic_test_mags_nonan.shape)\n",
    "\n",
    "n_historic_test_samp = len(historic_test_waves_nonan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a546a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### THE LOOP ###\n",
    "\n",
    "# Just using MLAAPDE or historic too?\n",
    "mlaa_only = False\n",
    "debug = False\n",
    "\n",
    "# for cut_len in weighted_cut_lens_test:\n",
    "for i in range(len(weighted_cut_lens)):\n",
    "    \n",
    "    cut_len = weighted_cut_lens[i]\n",
    "    h5num = weighted_h5nums[i]\n",
    "    \n",
    "    print('---------------------------------')\n",
    "    print('Cut len: ' + str(cut_len))\n",
    "    print('Shift len: ' + str(cut_len-6))\n",
    "        \n",
    "    ### ----- MLAAPDE DATA ----- ###\n",
    "    \n",
    "    ### ----- Cut and shift testing data to match the training data ----- ###\n",
    "    ## Cut ##\n",
    "    if debug:\n",
    "        rand = np.random.choice(np.arange(0,len(test_mags),1))\n",
    "        print('Rand: ' + str(rand))\n",
    "        test_times = np.arange(0, window_len, 1/sr)\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Original test data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(test_times, test_waves_t[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(test_times, test_waves_t[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(test_times, test_waves_t[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "    \n",
    "    middle = int(test_waves_t.shape[1] / 2)\n",
    "    if debug: print('Middle: ' + str(middle))\n",
    "    test_size = int(n_test_samp)\n",
    "    if debug: print('test size: ' + str(test_size))\n",
    "    cut_test_waves_t = np.zeros((test_size, int(cut_len*sr), 3)) \n",
    "    if debug: print('Cut waves t shape: ' + str(cut_test_waves_t.shape))\n",
    "\n",
    "    for i in range(len(test_waves_t)):\n",
    "        cut_test_waves_t[i,] = test_waves_t[i, int(middle - (cut_len/2)*sr) : int(middle + (cut_len/2)*sr), 0:3]\n",
    "    if debug: print('Cut waves t shape: ' + str(cut_test_waves_t.shape))\n",
    "    if debug:\n",
    "        test_cut_times = np.arange(0, cut_len, 1/sr)\n",
    "        print('Rand: ' + str(rand))\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Cut test data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(test_cut_times, cut_test_waves_t[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(test_cut_times, cut_test_waves_t[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(test_cut_times, cut_test_waves_t[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "\n",
    "    ## Shift ##\n",
    "    shift_len = cut_len - max_shift\n",
    "    if debug: print('Shift len: ' + str(shift_len))\n",
    "    time_offset = np.random.uniform(low = 0, high = max_shift, size = test_size)\n",
    "    shift_test_waves_t = np.zeros((test_size, int(shift_len * sr), 3)) \n",
    "\n",
    "    for ii, offset in enumerate(time_offset):\n",
    "        bin_offset = int(offset * sr)\n",
    "        start_bin = bin_offset \n",
    "        end_bin = int(start_bin + shift_len * sr)\n",
    "        shift_test_waves_t[ii, :, 0] = cut_test_waves_t[ii, start_bin:end_bin, 0] \n",
    "        shift_test_waves_t[ii, :, 1] = cut_test_waves_t[ii, start_bin:end_bin, 1]\n",
    "        shift_test_waves_t[ii, :, 2] = cut_test_waves_t[ii, start_bin:end_bin, 2]\n",
    "\n",
    "    if debug: print('Shift waves t shape: ' + str(shift_test_waves_t.shape))\n",
    "    if debug:\n",
    "        test_shift_times = np.arange(0, shift_len, 1/sr)\n",
    "        print('Rand: ' + str(rand))\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Shifted test data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(test_shift_times, shift_test_waves_t[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(test_shift_times, shift_test_waves_t[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(test_shift_times, shift_test_waves_t[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "        \n",
    "    ### ----- HISTORIC DATA ----- ###\n",
    "    \n",
    "    ## Cut ##\n",
    "    if debug:\n",
    "        rand = np.random.choice(np.arange(0,len(historic_test_mags_nonan),1))\n",
    "        print('Rand: ' + str(rand))\n",
    "        historic_test_times = np.arange(0, window_len, 1/sr)\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Original historic test data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(historic_test_times, historic_test_waves_nonan[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(historic_test_times, historic_test_waves_nonan[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(historic_test_times, historic_test_waves_nonan[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "\n",
    "    middle = int(historic_test_waves_nonan.shape[1] / 2)\n",
    "    if debug: print('Middle: ' + str(middle))\n",
    "    historic_test_size = int(n_historic_test_samp)\n",
    "    if debug: print('historic test size: ' + str(historic_test_size))\n",
    "    cut_historic_test_waves_nonan = np.zeros((historic_test_size, int(cut_len*sr), 3)) \n",
    "    if debug: print('Cut waves shape: ' + str(cut_historic_test_waves_nonan.shape))\n",
    "\n",
    "    for i in range(len(historic_test_waves_nonan)):\n",
    "        cut_historic_test_waves_nonan[i,] = historic_test_waves_nonan[i, int(middle - (cut_len/2)*sr) : int(middle + (cut_len/2)*sr), 0:3]\n",
    "    if debug: print('Cut waves shape: ' + str(cut_historic_test_waves_nonan.shape))\n",
    "    if debug:\n",
    "        historic_test_cut_times = np.arange(0, cut_len, 1/sr)\n",
    "        print('Rand: ' + str(rand))\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Cut historic test data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(historic_test_cut_times, cut_historic_test_waves_nonan[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(historic_test_cut_times, cut_historic_test_waves_nonan[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(historic_test_cut_times, cut_historic_test_waves_nonan[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "\n",
    "    ## Shift ##\n",
    "    shift_len = cut_len - max_shift\n",
    "    if debug: print('Shift len: ' + str(shift_len))\n",
    "    time_offset = np.random.uniform(low = 0, high = max_shift, size = historic_test_size)\n",
    "    shift_historic_test_waves_nonan = np.zeros((historic_test_size, int(shift_len * sr), 3)) \n",
    "\n",
    "    for ii, offset in enumerate(time_offset):\n",
    "        bin_offset = int(offset * sr)\n",
    "        start_bin = bin_offset \n",
    "        end_bin = int(start_bin + shift_len * sr)\n",
    "        shift_historic_test_waves_nonan[ii, :, 0] = cut_historic_test_waves_nonan[ii, start_bin:end_bin, 0] \n",
    "        shift_historic_test_waves_nonan[ii, :, 1] = cut_historic_test_waves_nonan[ii, start_bin:end_bin, 1]\n",
    "        shift_historic_test_waves_nonan[ii, :, 2] = cut_historic_test_waves_nonan[ii, start_bin:end_bin, 2]\n",
    "\n",
    "    if debug: print('Shift waves shape: ' + str(shift_historic_test_waves_nonan.shape))\n",
    "    if debug:\n",
    "        historic_test_shift_times = np.arange(0, shift_len, 1/sr)\n",
    "        print('Rand: ' + str(rand))\n",
    "        plt.figure(facecolor = 'white')\n",
    "        plt.suptitle('Shifted historic test data')\n",
    "        plt.subplot(311)\n",
    "        plt.plot(historic_test_shift_times, shift_historic_test_waves_nonan[rand,:,0], color = 'C0')\n",
    "        plt.subplot(312)\n",
    "        plt.plot(historic_test_shift_times, shift_historic_test_waves_nonan[rand,:,1], color = 'C1')\n",
    "        plt.subplot(313)\n",
    "        plt.plot(historic_test_shift_times, shift_historic_test_waves_nonan[rand,:,2], color = 'C2')\n",
    "        plt.subplots_adjust(hspace = 0)\n",
    "        plt.show();\n",
    "\n",
    "    ### ----- Initialize the model and training setup ----- ###\n",
    "\n",
    "    inp1 = tf.keras.layers.Input(shape = (sr*(cut_len - max_shift), n_channels), name = 'input_layer') \n",
    "    e = tf.keras.layers.Conv1D(filters[1], 3, padding = 'same')(inp1) \n",
    "    e = tf.keras.layers.Dropout(drop_rate)(e, training = True)\n",
    "    e = tf.keras.layers.MaxPooling1D(4, padding = 'same')(e)\n",
    "    e = tf.keras.layers.Conv1D(filters[0], 3, padding = 'same')(e) \n",
    "    e = tf.keras.layers.Dropout(drop_rate)(e, training = True)\n",
    "    e = tf.keras.layers.MaxPooling1D(4, padding = 'same')(e)\n",
    "    e = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences = False, dropout = 0.0, recurrent_dropout = 0.0))(e)\n",
    "    e = tf.keras.layers.Dense(1)(e)\n",
    "    o = tf.keras.layers.Activation('linear', name = 'output_layer')(e)\n",
    "    model = tf.keras.models.Model(inputs = [inp1], outputs = o)\n",
    "    #model.summary()\n",
    "\n",
    "    #model.compile(optimizer = 'Adam', loss = customLoss)\n",
    "    model.compile(optimizer = 'Adam', loss = tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "    model_name = str(dataset) + '_' + str(nsamp) + 'samps_' + str(shift_len) + 's'\n",
    "    m_name = str(model_name) + '_{epoch:03d}.h5' \n",
    "    \n",
    "    ### ----- Combine the MLAAPDE and historic testing data ----- ###\n",
    "\n",
    "    all_test_waves = np.concatenate((shift_test_waves_t, shift_historic_test_waves_nonan))\n",
    "    # print(all_test_waves.shape)\n",
    "    all_test_mags = np.concatenate((test_mags, historic_test_mags_nonan))\n",
    "    # print(all_test_mags.shape)\n",
    "\n",
    "    all_test_mags = np.round_(all_test_mags, decimals = 1) # Get rid of extra digits\n",
    "\n",
    "    ### ----- What trained model are we loading? ----- ###\n",
    "    \n",
    "    model_path = model_folder_path + training_dataset + '_' + str(nsamp) + 'samps_' + str(shift_len) + 's_window/'\n",
    "    # print(model_path)\n",
    "    list_of_models = glob.glob(model_path + '*.h5') # * means all if need specific format then *.csv\n",
    "    # print(list_of_models)\n",
    "    numbers = []\n",
    "    for item in list_of_models:\n",
    "        numbers.append(item[-6:-3])\n",
    "#     latest_model = model_path + training_dataset + '_' + str(nsamp) + 'samps_' + str(shift_len) + 's_' + max(numbers) + '.h5'\n",
    "    latest_model = model_path + training_dataset + '_' + str(nsamp) + 'samps_' + str(shift_len) + 's_' + h5num + '.h5'\n",
    "    print('Model: ' + str(latest_model))\n",
    "\n",
    "    print('Loading weights...')\n",
    "    model.load_weights(latest_model)\n",
    "    \n",
    "    ### ----- Make the predictions ----- ###\n",
    "    \n",
    "    print('Predicting...')\n",
    "    if mlaa_only == False:\n",
    "        predict_all = model.predict(all_test_waves)\n",
    "        all_test_mags = all_test_mags\n",
    "        tag = '_all_test'\n",
    "        np.save('/home/sdybing/mlaapde/testdata_preds/weighted_training/mag_preds/' + str(cut_len-6) + 's_window_magpreds.npy', predict_all)\n",
    "        \n",
    "    if mlaa_only == True:\n",
    "        predict_all = model.predict(shift_test_waves_t)\n",
    "        all_test_mags = test_mags\n",
    "        tag = '_mlaa_only'\n",
    "        np.save('/home/sdybing/mlaapde/testdata_preds/weighted_training/mag_preds/' + str(cut_len-6) + 's_window_magpreds_mlaa_only.npy', predict_all)\n",
    "\n",
    "    # print(predict_all.shape)\n",
    "    \n",
    "    ## ----- Quick plot of the predictions vs. true magnitudes ----- ###\n",
    "\n",
    "    fig4, ax = plt.subplots(facecolor = 'white')\n",
    "    ax.scatter(all_test_mags, predict_all, alpha = 0.4, facecolors = 'r', edgecolors = 'r')\n",
    "    ax.plot([all_test_mags.min(), all_test_mags.max()], [all_test_mags.min(), all_test_mags.max()], 'k--', alpha=1, lw=2)\n",
    "    ax.set_xlabel('Measured magnitude')\n",
    "    ax.set_ylabel('Predicted magnitude')\n",
    "#     plt.show()\n",
    "    fig4.savefig(models_figs_path + 'scatter_plots/' + str(cut_len-6) + 's_window_scatter_pred_vs_cat.png')\n",
    "    plt.close();\n",
    "    \n",
    "    ### ----- Rename things ----- ###\n",
    "\n",
    "    measured_mags = all_test_mags\n",
    "    predicted_mags = predict_all.flatten()\n",
    "\n",
    "    ### ----- Calculate the error and standard deviation ----- ###\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    for idx in range(len(predicted_mags)):\n",
    "        predicted = predicted_mags[idx]\n",
    "        measured = measured_mags[idx]\n",
    "        error = predicted - measured\n",
    "        errors.append(error)\n",
    "        \n",
    "    mean_error = np.mean(np.array(errors))\n",
    "    std_error = np.std(np.array(errors))\n",
    "    \n",
    "    # print('Error shape: ' + str(np.array(errors).shape))\n",
    "    \n",
    "    if mlaa_only == False:\n",
    "        np.savetxt('/home/sdybing/mlaapde/testdata_preds/weighted_training/errors/' + str(cut_len-6) + 's_window_errors.txt', np.array(errors))\n",
    "        \n",
    "    if mlaa_only == True:\n",
    "        np.savetxt('/home/sdybing/mlaapde/testdata_preds/weighted_training/mlaa_only/test_errors_' + str(cut_len-6) + 's_window_errors.txt', np.array(errors))\n",
    "\n",
    "    print('Mean error: ' + str(round(mean_error,3)))\n",
    "    print('Error standard deviation: ' + str(round(std_error,2)))\n",
    "    \n",
    "#     plt.figure(figsize = (8,6), dpi = 300)\n",
    "#     plt.hist(errors, bins = 50, color = '#2DADB4')\n",
    "#     plt.title(str(shift_len) + 's window: magnitude prediction errors', fontsize = 18)\n",
    "#     plt.xlabel('Predicted - catalog magnitude', fontsize = 14)\n",
    "#     plt.ylabel('Count', fontsize = 14)\n",
    "#     plt.xticks(fontsize = 12)\n",
    "#     plt.yticks(fontsize = 12)\n",
    "#     plt.text(x = -0.055, y = 0.495, s = 'Mean: ' + str(round(mean_error,2)) + '\\nSTD: ' + str(round(std_error,2)), fontsize = 18, backgroundcolor = 'lightgray', transform = ax.transAxes)\n",
    "#     plt.savefig(save_dir + '/error_histogram_' + m_name + '.png', format = 'PNG', facecolor = 'white', transparent = False);\n",
    "#     # plt.show();\n",
    "\n",
    "    mean_errors.append(mean_error)\n",
    "    std_errors.append(std_error)\n",
    "\n",
    "    ### ----- Make the box and whisker plots with STF magnitude line ----- ###\n",
    "\n",
    "    Tt = shift_len / 2\n",
    "    M0_dyncm = Tt**3 * (0.625 * 10**23)\n",
    "    Mw = ((2/3) * np.log10(M0_dyncm)) - 10.73 # M0 in dyne-cm\n",
    "\n",
    "    # print('Rupture duration: ' + str(Tt) + ' seconds')\n",
    "    # print('M0: ' + str(M0_dyncm) + ' dyne-cm')\n",
    "    # print('Mw: ' + str(round(Mw,2)))\n",
    "\n",
    "    bins = np.arange(7,92,1)/10\n",
    "    data_bins = []\n",
    "\n",
    "    for abin in bins:\n",
    "    #     print(abin)\n",
    "        i = np.where(measured_mags == abin)[0]\n",
    "    #     print(measured_mags[i])\n",
    "        predict_bin = np.array(predicted_mags[i])\n",
    "    #     print(predict_bin)\n",
    "        data_bins.append(predict_bin)\n",
    "    #     print('-----')\n",
    "    \n",
    "    # ----- Calculate statistics for bins ----- #\n",
    "    \n",
    "    print('Calculating and saving bin stats...')\n",
    "    \n",
    "    Q1s = []\n",
    "    Q3s = []\n",
    "    IQRs = []\n",
    "    medians = []\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    for idx in range(len(data_bins)):\n",
    "        # print('-----------')\n",
    "        \n",
    "        try:\n",
    "            data = data_bins[idx]\n",
    "            # print(data)\n",
    "            Q1 = np.quantile(data, 0.25)\n",
    "            Q3 = np.quantile(data, 0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            median = np.median(data)\n",
    "            mean = np.mean(data)\n",
    "            std = np.std(data)\n",
    "\n",
    "        #     print('Q1: ' + str(Q1))\n",
    "        #     print('Q3: ' + str(Q3))\n",
    "        #     print('IQR: ' + str(IQR))\n",
    "        #     print('Median: ' + str(median))\n",
    "        #     print('Mean: ' + str(mean))\n",
    "        #     print('Standard deviation: ' + str(std))\n",
    "\n",
    "            Q1s.append(Q1)\n",
    "            Q3s.append(Q3)\n",
    "            IQRs.append(IQR)\n",
    "            medians.append(median)\n",
    "            means.append(mean)\n",
    "            stds.append(std)\n",
    "\n",
    "        except: # if bin is empty\n",
    "            Q1s.append('nan')\n",
    "            Q3s.append('nan')\n",
    "            IQRs.append('nan')\n",
    "            medians.append('nan')\n",
    "            means.append('nan')\n",
    "            stds.append('nan')\n",
    "\n",
    "    # print(len(Q1s))\n",
    "    # print(len(Q3s))\n",
    "    # print(len(IQRs))\n",
    "    # print(len(medians))\n",
    "    # print(len(means))\n",
    "    # print(len(stds))\n",
    "\n",
    "    # ----- Where to save stats ----- #\n",
    "    \n",
    "    stats_save_dir = '/home/sdybing/mlaapde/testdata_preds/weighted_training/boxplot_stats/' + str(cut_len-6) + 's_window/'\n",
    "    if os.path.isdir(stats_save_dir):\n",
    "        pass\n",
    "    else: # deletes directory to start over: shutil.rmtree(save_dir)  \n",
    "        os.makedirs(stats_save_dir)\n",
    "\n",
    "    np.save(stats_save_dir + str(cut_len-6) + 's_window_Q1s.npy', np.array(Q1s))\n",
    "    np.save(stats_save_dir + str(cut_len-6) + 's_window_Q3s.npy', np.array(Q3s))\n",
    "    np.save(stats_save_dir + str(cut_len-6) + 's_window_IQRs.npy', np.array(IQRs))\n",
    "    np.save(stats_save_dir + str(cut_len-6) + 's_window_medians.npy', np.array(medians))\n",
    "    np.save(stats_save_dir + str(cut_len-6) + 's_window_means.npy', np.array(means))\n",
    "    np.save(stats_save_dir + str(cut_len-6) + 's_window_stds.npy', np.array(stds))\n",
    "    \n",
    "    # ----- Make boxplot ----- #\n",
    "\n",
    "    fig = plt.figure(figsize = (14, 9), dpi = 300, facecolor = 'white')\n",
    "\n",
    "    plt.rcParams['text.usetex'] = False\n",
    "\n",
    "    fig.suptitle(str(shift_len) + 's window', fontsize = 20, y = 0.93, color = 'black')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_facecolor('white')\n",
    "    # ax.text(x = 30, y = 8.8, s = 'Model: ' + m_name, fontsize = 13, color = 'black')\n",
    "    ax.grid(which = 'major', axis = 'y', markevery = 0.5, zorder = 2)\n",
    "    ax.grid(which = 'major', axis = 'x', zorder = 2.5)\n",
    "    ax.set_ylim(0,9.2)\n",
    "\n",
    "    bp = ax.boxplot(data_bins, notch = False, patch_artist = True, zorder = 3)\n",
    "\n",
    "    both_test_mags = [test_mags*10-6, historic_test_mags_nonan*10-6]\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.hist(both_test_mags, bins = 85, color = ['#730114', '#f01f42'], stacked = True, zorder = 3.5)\n",
    "    ax2.set_ylim(0,110000)\n",
    "    ax2.set_yticks([0, 10000, 20000])\n",
    "    ax2.set_yticklabels(['0', '10,000', '20,000'], style = 'italic')\n",
    "    # ax2.set_ylabel('Count of waveforms in each magnitude bin', fontsize = 16, color = 'black', rotation = 270, labelpad = 18)\n",
    "    ax2.text(s = 'Count of waveforms\\nin each magnitude bin', x = 86.5, y = 26000, fontsize = 16, color = 'black', rotation = 270, style = 'italic')\n",
    "    ax2.tick_params(labelsize = 14, color = 'black')\n",
    "    ax2.set_zorder(3.5)\n",
    "\n",
    "    ax2.axvline(((Mw*10)-6), color = 'blue', linestyle = '--', linewidth = 2, zorder = 20)\n",
    "\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor('#72d1d6')\n",
    "        patch.set_edgecolor('#001528')\n",
    "    for median in bp['medians']:\n",
    "        median.set(color = '#001528', linewidth = 3)\n",
    "    for whisker in bp['whiskers']:\n",
    "        whisker.set(color = '#001528', linewidth = 1)\n",
    "    for cap in bp['caps']:\n",
    "        cap.set(color = '#001528', linewidth = 1)\n",
    "    for flier in bp['fliers']:\n",
    "        flier.set(marker = '+', color = '#001528', alpha = 0.5)\n",
    "\n",
    "    bins_list = bins.tolist()\n",
    "    ax.set_xticklabels(bins_list, fontsize = 14, color = 'black')\n",
    "    ax.xaxis.set_major_locator(ticker.FixedLocator([4, 14, 24, 34, 44, 54, 64, 74, 84]))\n",
    "    ax.set_yticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    ax.tick_params(labelsize = 14, color = 'black')\n",
    "    ax.set_ylabel('Predicted magnitude', fontsize = 16, color = 'black')\n",
    "    ax.set_xlabel('Catalog magnitude', fontsize = 16, color = 'black')\n",
    "\n",
    "    linex = [4, 14, 24, 34, 44, 54, 64, 74, 84]\n",
    "    liney = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    liney05u = [1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n",
    "    liney05d = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5]\n",
    "\n",
    "    ax.plot(linex, liney, 'black', linestyle = '--', linewidth = 3, alpha = 0.4)\n",
    "    ax.plot(linex, liney05u, 'gray', linestyle = '--', linewidth = 2, alpha = 0.4)\n",
    "    ax.plot(linex, liney05d, 'gray', linestyle = '--', linewidth = 2, alpha = 0.4)\n",
    "    ax2.text(s = 'Testing data results', x = 2, y = 104000, fontsize = 18, backgroundcolor = '#72d1d6', color = 'black', zorder = 25)\n",
    "    ax2.text(s = 'STF magnitude: ' + str(round(Mw,2)), x = 2, y = 96500, fontsize = 18, backgroundcolor = 'blue', color = 'white', zorder = 25)\n",
    "    ax2.text(s = 'MLAAPDE test data distrib.', x = 57.8, y = 20000, fontsize = 18, backgroundcolor = '#730114', color = 'white', zorder = 25)\n",
    "    ax2.text(s = 'Historic test data distrib.', x = 59.85, y = 12500, fontsize = 18, backgroundcolor = '#f01f42', color = 'white', zorder = 25)\n",
    "\n",
    "#     plt.show();\n",
    "#     plt.savefig(save_dir + '/boxplot_durline_' + m_name + '.png', format = 'PNG', facecolor = 'white', transparent = False)\n",
    "#     plt.savefig('/home/sdybing/mlaapde/figures/testing/boxplots/' + str(cut_len-6) + 's_window.png', format = 'PNG', facecolor = 'white', transparent = False)\n",
    "    plt.savefig(models_figs_path + 'boxplots/' + str(cut_len-6) + 's_window_boxplot_pred_vs_cat.png', format = 'PNG', facecolor = 'white', transparent = False)\n",
    "    plt.close();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('/home/sdybing/mlaapde/testdata_preds/weighted_training/meanerrors.txt', np.array(mean_errors))\n",
    "np.savetxt('/home/sdybing/mlaapde/testdata_preds/weighted_training/stderrors.txt', np.array(std_errors))\n",
    "np.savetxt('/home/sdybing/mlaapde/testdata_preds/weighted_training/medianerrors.txt', np.array(median_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weighted_cut_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abe9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mean_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f54cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- Plot error and std for all windows ----- ###\n",
    "\n",
    "weighted_shift_lengths = []\n",
    "\n",
    "for cut_len in weighted_cut_lens:\n",
    "    shift_len = cut_len - max_shift\n",
    "    weighted_shift_lengths.append(shift_len)\n",
    "    \n",
    "plt.figure(figsize = (10, 6), dpi = 300, facecolor = 'white')\n",
    "plt.title('Testing errors/stds: weighted models trained with\\n2.92 million augmented samples shifted up to 3 seconds', fontsize = 16)\n",
    "plt.errorbar(weighted_shift_lengths, mean_errors, color = '#001528', yerr = std_errors, fmt = '.', markersize = 10, ecolor = '#f01f42', capsize = 3, label = 'Error bars show 1 standard\\ndeviation above each point and\\n1 standard deviation below')\n",
    "# plt.scatter(shift_lengths, mean_errors, color = '#2DADB4')\n",
    "plt.grid()\n",
    "plt.xlabel('Window length (s)', fontsize = 14)\n",
    "plt.ylabel('Mean error\\n(Predicted - catalog magnitude)', fontsize = 14)\n",
    "plt.xticks(fontsize = 13)\n",
    "plt.yticks(fontsize = 13)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.axhline(0, color = 'black', linestyle = '--', alpha = 0.75)\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig('/home/sdybing/mlaapde/testdata_preds/weighted_training/meanstderror_timeplot.png', format = 'PNG', facecolor = 'white', transparent = False)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41498ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_meanerrors = np.loadtxt('/home/sdybing/mlaapde/testdata_preds/all_test_rerun/meanerrors.txt')\n",
    "original_medianerrors = np.loadtxt('/home/sdybing/mlaapde/testdata_preds/all_test_rerun/medianerrors.txt')\n",
    "original_stderrors = np.loadtxt('/home/sdybing/mlaapde/testdata_preds/all_test_rerun/stderrors.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_lengths = []\n",
    "\n",
    "for cut_len in cut_lens:\n",
    "    shift_len = cut_len - max_shift\n",
    "    shift_lengths.append(shift_len)\n",
    "    \n",
    "plt.figure(figsize = (10, 6), dpi = 300, facecolor = 'white')\n",
    "plt.title('Testing errors/stds by training method', fontsize = 16)\n",
    "plt.errorbar(shift_lengths, original_medianerrors, color = '#001528', yerr = original_stderrors, fmt = '.', markersize = 10, ecolor = '#f01f42', capsize = 3, label = 'Original training')\n",
    "plt.errorbar(weighted_shift_lengths, median_errors, color = '#68A2B9', yerr = std_errors, fmt = 'v', markersize = 7, fillstyle = 'none', ecolor = '#68A2B9', capsize = 3, label = 'Weighted training')\n",
    "# plt.scatter(shift_lengths, mean_errors, color = '#2DADB4')\n",
    "plt.grid()\n",
    "plt.xlabel('Window length (s)', fontsize = 14)\n",
    "plt.ylabel('Mean error\\n(Predicted - catalog magnitude)', fontsize = 14)\n",
    "plt.xticks(fontsize = 13)\n",
    "plt.yticks(fontsize = 13)\n",
    "plt.legend(fontsize = 12)\n",
    "plt.axhline(0, color = 'black', linestyle = '--', alpha = 0.75)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('/home/sdybing/mlaapde/testdata_preds/weighted_training/meanstderror_timeplot_comparetrainings.png', format = 'PNG', facecolor = 'white', transparent = False)\n",
    "# plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36c1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
